{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635962d3-39cc-4ec9-ab97-1ad7154d0169",
   "metadata": {},
   "source": [
    "#### **This notebook test for different algorithm results for tweet classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16f81fc-22da-4acd-a836-69718dfbb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "#### packages\n",
    "import helper.strategy_helper as st\n",
    "import helper.visualization as viz_hp\n",
    "import config.config as config_hp\n",
    "import matplotlib.pyplot as plt\n",
    "import helper.stat_helper as stat_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b8f96f-6d14-4bf0-95aa-4037125af247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12d6e3-6840-4a59-94ed-9083ad08c219",
   "metadata": {},
   "source": [
    "#### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185afe94-aece-4d9f-9a47-3ef5c1d91f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stat_hp)\n",
    "\n",
    "import importlib\n",
    "\n",
    "tweet_features = './../data/RQ2_tweet_classifier_features.csv'\n",
    "\n",
    "df_all_stat = pd.read_csv(tweet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "968c09a8-e6a9-40b3-9dbe-15b65a6b665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of features:  99\n"
     ]
    }
   ],
   "source": [
    "print('No. of features: ', len(df_all_stat.columns)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3cbe4a-d630-49db-9705-5b6503818cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features with target: \n",
      " Index(['std_retweet_count', 'range_reply_count', 'entropy_num_hashtags',\n",
      "       'std_num_url', 'kurtosis_like_count', 'range_like_count',\n",
      "       'skew_like_count', 'skew_reply_count', '50%_mention_count',\n",
      "       'kurtosis_cosine',\n",
      "       ...\n",
      "       'max_like_count', 'mean_diff_min', 'entropy_retweet_count',\n",
      "       'mean_retweet_count', 'min_cosine', 'max_num_hashtags',\n",
      "       'entropy_mention_count', 'range_num_hashtags', 'entropy_cosine',\n",
      "       'range_retweet_count'],\n",
      "      dtype='object', length=101)\n"
     ]
    }
   ],
   "source": [
    "print('All features with target: \\n', df_all_stat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e0cef-5e47-43ae-bb2c-9bc6e272364d",
   "metadata": {},
   "source": [
    "#### **Code to train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16965308-1650-4d13-8382-4de319b4f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def run_model(df,\n",
    "              columns_not_include=[],\n",
    "              model_type='random', \n",
    "              y_column = 'tweet_label',\n",
    "              filename=None,\n",
    "             ):\n",
    "    '''\n",
    "    Trains the model and prints the result\n",
    "    :param df: Dataframe\n",
    "    :param model_type: Type of model\n",
    "    :param pca: Whether to do PCA or not\n",
    "    :param columns_not_include: columns to not include\n",
    "    '''\n",
    "    print(f'\\n **** {model_type} ****')\n",
    "    \n",
    "    ### Remove unnecessary columns\n",
    "    import pickle\n",
    "\n",
    "    model_filename = filename\n",
    "    \n",
    "    columns_not_include.extend(\n",
    "        ['poster_tweetid','tweet_label', 'replier_userid', 'replier_label'])\n",
    "    \n",
    "    columns_to_keep = list(set(df.columns) - set(columns_not_include))\n",
    "\n",
    "    X = df[columns_to_keep]\n",
    "    y = df[y_column]\n",
    "  \n",
    "    ### Choose model\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(random_state=0)\n",
    "    elif model_type == 'random':\n",
    "        print('Running Random Forest')\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                   random_state=42\n",
    "                                  )\n",
    "    elif model_type == 'ada':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier(n_estimators=100,\n",
    "                                 algorithm=\"SAMME\", \n",
    "                                   random_state=0\n",
    "                                  )\n",
    "    elif model_type == 'tree':\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    elif model_type == 'naive':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    ### Choose scoring function\n",
    "    from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "    # Creating a dictionary of scorers\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, average='binary'),\n",
    "        'recall': make_scorer(recall_score, average='binary'),\n",
    "        'f1': make_scorer(f1_score, average='binary'),\n",
    "        'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n",
    "    }\n",
    "\n",
    "    cv_scores = [\n",
    "        \"train_precision\",\n",
    "        \"test_precision\",\n",
    "        \"train_recall\",\n",
    "        \"test_recall\",\n",
    "        \"train_f1\",\n",
    "        \"test_f1\",\n",
    "        \"train_roc_auc\",\n",
    "        \"test_roc_auc\",\n",
    "    ]\n",
    "\n",
    "    from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    #Creates a pipeline for training and testing\n",
    "    #Standardize the features\n",
    "    #Stratified5Fold cross validation\n",
    "    #F1 as scoring function\n",
    "    #TunedThresholdClassifierCV: for each cross-validation\n",
    "    #this returns all the scores in cross validation\n",
    "    #as well as the model trained in all data tuned with best threshold \n",
    "    #during cross-validation\n",
    "    \n",
    "    model = make_pipeline(StandardScaler(), model)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=42)\n",
    "    tuned_model = TunedThresholdClassifierCV(estimator=model,\n",
    "                                             scoring='f1',\n",
    "                                             store_cv_results = True,\n",
    "                                             n_jobs=-1\n",
    "                                            )\n",
    "\n",
    "    cv_results_tuned_model = pd.DataFrame(\n",
    "        cross_validate(\n",
    "            tuned_model,\n",
    "            X,\n",
    "            y,\n",
    "            scoring=scoring,\n",
    "            cv=cv,\n",
    "            return_train_score=True,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "    )\n",
    "   \n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    decision_threshold = pd.Series(\n",
    "        [est.best_threshold_ for est in cv_results_tuned_model[\"estimator\"]],\n",
    "    )\n",
    "    cv_results_tuned_model['threshold'] = decision_threshold\n",
    "    \n",
    "    cv_results_tuned_model['algorithm'] = model_type\n",
    "    \n",
    "    return cv_results_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05233a-c601-4bbd-8d6c-442aed707f86",
   "metadata": {},
   "source": [
    "#### **Run for all algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbfbde-2acf-4de8-9f24-8fd48a968d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithms = ['logistic', 'ada', 'random', 'tree', 'naive']\n",
    "all_results = []\n",
    "for algo in algorithms:\n",
    "    df_result = run_model(df_all_stat,\n",
    "                   columns_not_include=['list_age'],\n",
    "                   model_type=algo, \n",
    "                   y_column = 'tweet_label',\n",
    "                   filename=None,\n",
    "                  )\n",
    "    \n",
    "    all_results.append(df_result)\n",
    "    \n",
    "(pd.concat(all_results, ignore_index=True)\n",
    ").to_pickle('./../results/tweet_classifier_different_algorithm.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c9601-24a6-4f5f-aed7-2f17226dae6d",
   "metadata": {},
   "source": [
    "#### **Load the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff25b101-d715-4835-88e4-9f009ad3c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_pickle(\n",
    "    './../results/tweet_classifier_different_algorithm.pkl.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a41a7a6-d292-41ec-b711-825577d79a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['test_precision', 'test_recall',\n",
    "           'test_f1', 'test_roc_auc',\n",
    "           'algorithm'\n",
    "          ]\n",
    "df_grp = (df_result[columns]\n",
    "          .groupby(['algorithm'])\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          .sort_values(by='test_roc_auc',\n",
    "                       ascending=False\n",
    "                      )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31a576af-8eb9-483c-98d2-3f9a61c00475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['algorithm', 'test_precision', 'test_recall', 'test_f1',\n",
       "       'test_roc_auc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "761eadc2-51a8-4611-8d55-fb6399f57e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random</td>\n",
       "      <td>0.738555</td>\n",
       "      <td>0.878118</td>\n",
       "      <td>0.801964</td>\n",
       "      <td>0.884198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.646652</td>\n",
       "      <td>0.891828</td>\n",
       "      <td>0.749283</td>\n",
       "      <td>0.812638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.657619</td>\n",
       "      <td>0.862572</td>\n",
       "      <td>0.745949</td>\n",
       "      <td>0.803156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.522464</td>\n",
       "      <td>0.956309</td>\n",
       "      <td>0.665887</td>\n",
       "      <td>0.699343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naive</td>\n",
       "      <td>0.494626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661873</td>\n",
       "      <td>0.685112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm  test_precision  test_recall   test_f1  test_roc_auc\n",
       "3    random        0.738555     0.878118  0.801964      0.884198\n",
       "0       ada        0.646652     0.891828  0.749283      0.812638\n",
       "1  logistic        0.657619     0.862572  0.745949      0.803156\n",
       "4      tree        0.522464     0.956309  0.665887      0.699343\n",
       "2     naive        0.494626     1.000000  0.661873      0.685112"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3007cc-67e7-4c3d-ae2d-4f801c18fce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_standard_error(values, label):\n",
    "    '''\n",
    "    Calculates the standard error\n",
    "    :param values: List of values to calculate the\n",
    "    standard deviation and mean\n",
    "    :param label: What is the label for values\n",
    "\n",
    "    :return mean_values: Mean of values\n",
    "    :return std_values: Standard deviation from mean\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "    \n",
    "    mean_values = np.mean(values)\n",
    "    \n",
    "    # Standard deviation as error bars\n",
    "    std_values = np.std(values)\n",
    "    error = std_values/(np.sqrt(len(values)))\n",
    "\n",
    "    print(f\"Mean {label}: {mean_values:.3f} ± standard error {error}\")\n",
    "\n",
    "    return mean_values, std_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69264f36-f00c-4eb5-aba6-adec0d768de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : ada\n",
      "Mean precision: 0.647 ± standard error 0.002208958853097435\n",
      "Mean recall: 0.892 ± standard error 0.0033999301346241597\n",
      "Mean f1: 0.749 ± standard error 0.0009829964361432405\n",
      "Mean AUC: 0.813 ± standard error 0.0011568361817921474\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n",
      "Algorithm : logistic\n",
      "Mean precision: 0.658 ± standard error 0.0019474902940183534\n",
      "Mean recall: 0.863 ± standard error 0.0030967212309957674\n",
      "Mean f1: 0.746 ± standard error 0.0009926883617619366\n",
      "Mean AUC: 0.803 ± standard error 0.0012178880279946317\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n",
      "Algorithm : naive\n",
      "Mean precision: 0.495 ± standard error 1.8281269613566455e-05\n",
      "Mean recall: 1.000 ± standard error 0.0\n",
      "Mean f1: 0.662 ± standard error 1.6364951812737582e-05\n",
      "Mean AUC: 0.685 ± standard error 0.0017211828767611777\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n",
      "Algorithm : random\n",
      "Mean precision: 0.739 ± standard error 0.0026694748875367644\n",
      "Mean recall: 0.878 ± standard error 0.0024688878343244593\n",
      "Mean f1: 0.802 ± standard error 0.001163087918525277\n",
      "Mean AUC: 0.884 ± standard error 0.0009704708810871529\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n",
      "Algorithm : tree\n",
      "Mean precision: 0.522 ± standard error 0.009772794348802209\n",
      "Mean recall: 0.956 ± standard error 0.015341079185384571\n",
      "Mean f1: 0.666 ± standard error 0.0015115797747439113\n",
      "Mean AUC: 0.699 ± standard error 0.0015009868864349126\n",
      "\n",
      " ******************** \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grp = (df_result\n",
    "          .groupby(['algorithm'])\n",
    "         )\n",
    "\n",
    "for grp, df_values in df_grp:\n",
    "    print('Algorithm :', grp[0])\n",
    "    mean_precision, std_prec = print_standard_error(df_values['test_precision'],\n",
    "                                                    'precision'\n",
    "                                                   )\n",
    "\n",
    "    mean_recall , std_recall = print_standard_error(df_values['test_recall'],\n",
    "                                                    'recall'\n",
    "                                                   )\n",
    "    mean_f1 , std_f1 = print_standard_error(df_values['test_f1'],\n",
    "                                            'f1'\n",
    "                                           )\n",
    "    mean_auc , std_auc = print_standard_error(df_values['test_roc_auc'],\n",
    "                                              'AUC'\n",
    "                                             )\n",
    "\n",
    "    print('\\n ******************** \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ecdb8-4bc1-41c2-bbf1-90218eb206b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
