{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dee9d72-26b6-4b48-a753-5cfa5f5c537b",
   "metadata": {},
   "source": [
    "### **This notebook creates the test datat sets of positive and negative data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30987c1c-d871-45a1-b429-ef117d5bbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import importlib\n",
    "\n",
    "#### packages\n",
    "import helper.strategy_helper as st\n",
    "import helper.visualization as viz_hp\n",
    "import helper.helper as hp\n",
    "import helper.file_helper as file_hp\n",
    "import config.config as config_hp\n",
    "import helper.pandas_helper as pd_hp\n",
    "import helper.twitter_helper as twitter_hp\n",
    "import helper.slurm_helper as slurm_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8286f472-3373-439d-831f-66f91bd294e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_hp.config()\n",
    "poster_path = config['POSTER_PATH']\n",
    "path = config['PATHS']\n",
    "\n",
    "dead_tweets_path = poster_path['poster_dead_tweet_file']\n",
    "external_reply_path = path['external_reply']\n",
    "splited_reply_ids = path['splited_reply_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01208818-0d86-4d95-a3b3-01c98d393e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Get alive tweets : 34,185**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5679bf8-074f-4ee6-92ce-f78ac8fa7697",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Get 5 or more replies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fb7caa-5440-45ca-b036-b959e384fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_ids_5 = path['conversation_ids_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c44d92e-f156-4238-a572-b328d29824dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_ids_5 = file_hp.read_file(conversation_ids_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02348e79-f858-46ee-a0b0-81f8789b4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_external_replies = pd.read_pickle(external_reply_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fde2e9-b7a2-4061-865c-f7ef7dee7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_external_replies = df_external_replies.astype({\n",
    "    'poster_tweetid': int\n",
    "})\n",
    "\n",
    "df_external_replies = df_external_replies.astype({\n",
    "    'poster_tweetid': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7811e4-4256-4409-8c86-a741429d7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_external_replies.loc[\n",
    "    df_external_replies['poster_tweetid'].isin(conversation_ids_5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad9403-b0fc-4bae-84fb-db024f5f8205",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Remove dead tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b41a2a-bd90-47fa-8b3d-8c6533253d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_tweets = file_hp.read_file(dead_tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b906ceef-db6f-4c0d-97ae-12af46208ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dead tweets : 61856\n"
     ]
    }
   ],
   "source": [
    "print('Number of dead tweets :', \n",
    "      len(dead_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4131d6e0-9fba-45f7-bc9c-c0013df66d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34185"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5['poster_tweetid'].nunique() - len(dead_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d94e5ab-0657-4a91-b9fc-c82c09a55e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_5.astype({\n",
    "    'poster_tweetid': int\n",
    "})\n",
    "\n",
    "df_5 = df_5.astype({\n",
    "    'poster_tweetid': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2792cc6-df58-4928-ac93-4a8dd0515ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alive = df_5.loc[\n",
    "    ~df_5['poster_tweetid'].isin(dead_tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cab31a-f4d0-41b7-917c-64b030140951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alive['poster_tweetid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb92eda8-73f6-41c2-a448-3ec89a41b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 635261 entries, 973 to 21422171\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   replier_tweetid  635261 non-null  int64  \n",
      " 1   replier_userid   635261 non-null  object \n",
      " 2   poster_tweetid   635261 non-null  object \n",
      " 3   poster_userid    635261 non-null  float64\n",
      " 4   tweet_language   635261 non-null  object \n",
      " 5   tweet_text       635261 non-null  object \n",
      " 6   tweet_time       635261 non-null  object \n",
      " 7   year             635261 non-null  object \n",
      " 8   campaign         635261 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 48.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_alive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65215708-57f2-4b1e-bbcd-1930e7f518f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Get the whole conversations for the tweets (postive cases)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4746777a-630d-4555-8002-dd2979cc1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_reply_ids = path['splited_reply_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "73cf726b-0da0-422d-b00c-3ee0d3494d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_reply_5 = path['extracted_reply_5'] + os.sep + 'job_91_450_455.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9df5b8ff-93f3-4915-a630-24b658c89fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tweets(tweet_file, output_file=None):\n",
    "    '''\n",
    "    Parse the tweets\n",
    "    :param tweet_file: Raw tweet file\n",
    "    :param output_file: File to be saved. If none no file is saved\n",
    "    \n",
    "    :return Dataframe\n",
    "    '''\n",
    "    all_tweets = []\n",
    "    total = 0\n",
    "    with open(tweet_file, 'r') as json_file:\n",
    "        for row in json_file:\n",
    "            one_row = json.loads(row)\n",
    "            print(one_row.keys())\n",
    "            print(one_row['meta'])\n",
    "            # print(one_row['__twarc'])\n",
    "            # print(one_row['includes']['tweets'])\n",
    "            break\n",
    "            if 'errors' in one_row:\n",
    "                for values in one_row['errors']:\n",
    "                    tweet = set_values_for_tweet_with_error(values)\n",
    "                    \n",
    "                    if tweet != None:\n",
    "                        all_tweets.append(tweet)\n",
    "            \n",
    "            if 'data' not in one_row:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "649cb50e-356b-47a2-b742-9b69f4a41d58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/N/slate/potem/data/derived/extracted_conversation/extracted_reply_5/job_91_450_455.jsonl\n",
      "/N/slate/potem/data/derived/conversation/5_reply_count/job_91_450_455.txt\n",
      "5\n",
      "['1174602215970897920', '1198210261250953216', '1232644648310595584', '1105831383359021056', '855808001017610240']\n",
      "dict_keys(['data', 'includes', 'errors', 'meta', '__twarc'])\n",
      "{'newest_id': '1175105799686905857', 'oldest_id': '1174603626058276864', 'result_count': 34}\n",
      "Conversations \n",
      "4\n",
      "4\n",
      "{'1198210261250953216'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# df_all = pd.DataFrame()\n",
    "poster_alive_tweet_ids = poster_path['poster_alive_tweet_ids']\n",
    "alive_tweets = file_hp.read_file(poster_alive_tweet_ids)\n",
    "                                 \n",
    "for tweet_file in glob.glob(extracted_reply_5):\n",
    "    print(tweet_file)\n",
    "    parts = tweet_file.split(os.sep)[-1]\n",
    "    job_index = parts.split('_')[1]\n",
    "    file_part = parts.split('.')[0]+'.txt'\n",
    "    \n",
    "    # if int(job_index) < 60:\n",
    "    #     continue\n",
    "    \n",
    "    split_ids = splited_reply_ids+os.sep+file_part\n",
    "    print(split_ids)\n",
    "    id_file = file_hp.read_file(split_ids)\n",
    "    print(len(id_file))\n",
    "    print(id_file)\n",
    "    parse_tweets(tweet_file) \n",
    "    df_tweet = twitter_hp.parse_tweets(tweet_file)\n",
    "    # print(df_tweet)\n",
    "    print('Conversations ')\n",
    "    print(df_tweet['conversation_id'].nunique())\n",
    "    \n",
    "    df_conv = df_tweet.loc[df_tweet['conversation_id'].isin(id_file)]\n",
    "    print(df_conv['conversation_id'].nunique())\n",
    "    print(set(id_file) - set(df_conv['conversation_id'].unique().tolist()))\n",
    "    print('-----')\n",
    "    # break\n",
    "#     df_all = df_all.append(df_tweet)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95aa25b6-ff0f-4c32-9348-f12ede3d899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>author_id</th>\n",
       "      <th>...</th>\n",
       "      <th>impression_count</th>\n",
       "      <th>expanded_url</th>\n",
       "      <th>display_url</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>entity_annotations</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, conversation_id, lang, entities, possibly_sensitive, reply_settings, created_at, edit_history_tweet_ids, tweetid, author_id, retweet_count, reply_count, like_count, quote_count, impression_count, expanded_url, display_url, in_reply_to_user_id, referenced_tweets, context_annotations, entity_annotations, cashtags, hashtags, mentions]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tweet.loc[df_tweet['author_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61894b3e-9309-4c39-86f0-751878ff1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python_script='/N/u/potem/Quartz/project/infoOps-strategy/script/py_scripts/merge_jsonl_files.py'\n",
    "# job_name='combine_all_test_positive'\n",
    "# slurm_path=config['SLURM_PATH']['slurm_path']\n",
    "\n",
    "# slurm_hp.creat_and_despatch_job(python_script,\n",
    "                          #  job_name,\n",
    "                          #  slurm_path,\n",
    "                          #  despatch=True,\n",
    "                          #  logs_path=None\n",
    "                          # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83672eae-d70f-4f11-b671-827ffa76fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cancel_jobs(start_no, end_no):\n",
    "    '''\n",
    "    Cancels the jobs\n",
    "    :param start_no: starting job no\n",
    "    :param end_no: ending job no\n",
    "    '''\n",
    "    for i in range(start_no, end_no+1):\n",
    "        print(i)\n",
    "        command = f'scancel -u potem {i}'\n",
    "\n",
    "        os.system(command)\n",
    "# cancel_jobs(1471385, 1471424)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0fd40-1cf4-4c30-a4fc-622a14fdc68c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Positive cases: Merge all the tweets to create conversation thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4003b455-b07f-4fc7-9f8e-987d6faa30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive = config['TESTS']['test_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "146fc143-abee-4299-917a-85cc300dbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remaining_conv = pd.read_pickle(test_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c29463bf-258e-40ff-9524-22b982502047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'conversation_id', 'lang', 'entities', 'possibly_sensitive',\n",
       "       'reply_settings', 'created_at', 'edit_history_tweet_ids', 'tweetid',\n",
       "       'author_id', 'retweet_count', 'reply_count', 'like_count',\n",
       "       'quote_count', 'impression_count', 'expanded_url', 'display_url',\n",
       "       'in_reply_to_user_id', 'referenced_tweets', 'context_annotations',\n",
       "       'entity_annotations', 'cashtags', 'hashtags', 'mentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remaining_conv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee3b42ce-b116-4c49-9a49-e022df2530b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remaining_conv['conversation_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "494e0a2a-8918-480d-b49a-df9644f119af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1339908 entries, 0 to 129\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   text                    1339908 non-null  object \n",
      " 1   conversation_id         1339888 non-null  object \n",
      " 2   lang                    1339907 non-null  object \n",
      " 3   entities                0 non-null        object \n",
      " 4   possibly_sensitive      1339907 non-null  object \n",
      " 5   reply_settings          1339907 non-null  object \n",
      " 6   created_at              1339908 non-null  object \n",
      " 7   edit_history_tweet_ids  1339897 non-null  object \n",
      " 8   tweetid                 1339908 non-null  object \n",
      " 9   author_id               1339907 non-null  object \n",
      " 10  retweet_count           1339907 non-null  float64\n",
      " 11  reply_count             1339907 non-null  float64\n",
      " 12  like_count              1339907 non-null  float64\n",
      " 13  quote_count             1339907 non-null  float64\n",
      " 14  impression_count        1339907 non-null  float64\n",
      " 15  expanded_url            36172 non-null    object \n",
      " 16  display_url             36172 non-null    object \n",
      " 17  in_reply_to_user_id     1339907 non-null  object \n",
      " 18  referenced_tweets       1339907 non-null  object \n",
      " 19  context_annotations     36379 non-null    object \n",
      " 20  entity_annotations      304511 non-null   object \n",
      " 21  cashtags                75 non-null       object \n",
      " 22  hashtags                658386 non-null   object \n",
      " 23  mentions                1327837 non-null  object \n",
      "dtypes: float64(5), object(19)\n",
      "memory usage: 255.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_remaining_conv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbb7c137-ae4f-440a-ae63-3bcf8ef6101a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['replier_tweetid', 'replier_userid', 'poster_tweetid', 'poster_userid',\n",
       "       'tweet_language', 'tweet_text', 'tweet_time', 'year', 'campaign'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad13bfc5-cd42-4f6b-bec3-c27a0749a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 635261 entries, 973 to 21422171\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   replier_tweetid  635261 non-null  int64  \n",
      " 1   replier_userid   635261 non-null  object \n",
      " 2   poster_tweetid   635261 non-null  object \n",
      " 3   poster_userid    635261 non-null  float64\n",
      " 4   tweet_language   635261 non-null  object \n",
      " 5   tweet_text       635261 non-null  object \n",
      " 6   tweet_time       635261 non-null  object \n",
      " 7   year             635261 non-null  object \n",
      " 8   campaign         635261 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 48.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_alive_pos = df_alive.merge(df_remaining_conv,\n",
    "                          left_on='poster_tweetid',\n",
    "                          right_on='conversation_id',\n",
    "                         )\n",
    "df_alive_pos.info()                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84b9907-8489-459f-91e9-9a454db4e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_alive.['conversation_id']['.nunique()job_81_4000_4050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35053fda-2f87-49a0-9d5f-b48a637e57ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/N/slate/potem/data/derived/extracted_conversation/extracted_reply_5/*.jsonl*'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_reply_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4105e4ce-aaf5-4369-8fca-cc4715692c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ids  34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "ids_file = splited_reply_ids + os.sep + '*.txt'\n",
    "poster_dead_tweet_file = poster_path['poster_dead_tweet_file']\n",
    "\n",
    "dead_tweets = file_hp.read_file(poster_dead_tweet_file)\n",
    "\n",
    "for tweet_file in glob.glob(ids_file):\n",
    "    # parts = tweet_file.split(os.sep)[-1]\n",
    "    # file_part = parts.split('.')[0]+'.txt'\n",
    "    ids = file_hp.read_file(tweet_file)\n",
    "    print('File ids ', len(ids))\n",
    "    print(len(set(ids).intersection(set(dead_tweets))))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63ac0515-961b-41e8-bd28-3b540e77e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ids  24\n",
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n",
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n",
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n",
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n",
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n",
      "/tmp/ipykernel_1523787/1565245604.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'856441902069153792',\n",
       " '856443224172490752',\n",
       " '856608662470758400',\n",
       " '857318004211814400',\n",
       " '857320225376792576',\n",
       " '857337419473051648'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "test = []\n",
    "extracted_reply_5 = path['extracted_reply_5']\n",
    "for tweet_file in glob.glob(extracted_reply_5+os.sep+'job_81_4000_4050.jsonl'):\n",
    "    parts = tweet_file.split(os.sep)[-1]\n",
    "    file_part = parts.split('.')[0]+'.txt'\n",
    "    ids_file = splited_reply_ids + os.sep + file_part\n",
    "    ids = file_hp.read_file(ids_file)\n",
    "    print('File ids ', len(ids))\n",
    "    \n",
    "    with open(tweet_file, 'r') as json_file:\n",
    "        for row in json_file:\n",
    "            one_row = json.loads(row)\n",
    "            # print(one_row.keys())\n",
    "            df_all = df_all.append(\n",
    "                    twitter_hp.parse_tweets(tweet_file))\n",
    "            \n",
    "            for row in one_row['data']:\n",
    "                # print(row['conversation_id'])\n",
    "                test.append(row['conversation_id'])\n",
    "#                 break\n",
    "            \n",
    "#             break\n",
    "#         break\n",
    "\n",
    "\n",
    "print(len(set(test)))\n",
    "print(df_all['conversation_id'].nunique())\n",
    "#     print(tweet_file)\n",
    "#     parts = tweet_file.split(os.sep)[-1]\n",
    "#     job_index = parts.split('_')[1]\n",
    "#     file_part = parts.split('.')[0]+'.txt'\n",
    "    \n",
    "#     if int(job_index) <=60:\n",
    "#         continue\n",
    "    \n",
    "#     id_file = file_hp.read_file(\n",
    "#         splited_reply_ids+os.sep+file_part)\n",
    "#     print('length of id file ', len(id_file))\n",
    "#     # print(len(id_file))\n",
    "        \n",
    "# # #     print(tweet_file)\n",
    "  \n",
    "#     df_tweet = twitter_hp.parse_tweets(tweet_file)\n",
    "#     print(df_tweet['conversation_id'].nunique())\n",
    "    \n",
    "#     df_conv = df_tweet.loc[df_tweet['conversation_id'].isin(id_file)]\n",
    "#     print(df_conv['conversation_id'].nunique())\n",
    "#     print(set(id_file) - set(df_conv['conversation_id'].unique().tolist()))\n",
    "#     print('-----')\n",
    "#     df_all = df_all.append(df_tweet)\n",
    "    \n",
    "    # break\n",
    "    \n",
    "poster_dead_tweet_file = poster_path['poster_dead_tweet_file']\n",
    "\n",
    "dead_tweets = file_hp.read_file(poster_dead_tweet_file)\n",
    "set(test).intersection(set(dead_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f40be34-0a63-4cb3-a6b4-a8d2a78e44eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 516 entries, 0 to 85\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   text                    516 non-null    object\n",
      " 1   conversation_id         516 non-null    object\n",
      " 2   lang                    516 non-null    object\n",
      " 3   entities                0 non-null      object\n",
      " 4   possibly_sensitive      516 non-null    bool  \n",
      " 5   reply_settings          516 non-null    object\n",
      " 6   created_at              516 non-null    object\n",
      " 7   edit_history_tweet_ids  516 non-null    object\n",
      " 8   tweetid                 516 non-null    object\n",
      " 9   author_id               516 non-null    object\n",
      " 10  retweet_count           516 non-null    int64 \n",
      " 11  reply_count             516 non-null    int64 \n",
      " 12  like_count              516 non-null    int64 \n",
      " 13  quote_count             516 non-null    int64 \n",
      " 14  impression_count        516 non-null    int64 \n",
      " 15  expanded_url            6 non-null      object\n",
      " 16  display_url             6 non-null      object\n",
      " 17  in_reply_to_user_id     516 non-null    object\n",
      " 18  referenced_tweets       516 non-null    object\n",
      " 19  context_annotations     0 non-null      object\n",
      " 20  entity_annotations      132 non-null    object\n",
      " 21  cashtags                0 non-null      object\n",
      " 22  hashtags                138 non-null    object\n",
      " 23  mentions                450 non-null    object\n",
      "dtypes: bool(1), int64(5), object(18)\n",
      "memory usage: 97.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c704c-7e84-45f5-8eaa-ac3d580e76cf",
   "metadata": {},
   "source": [
    "##### **Negative cases: Get the conversations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1489e-2c96-4421-9aba-38ca09f0ab77",
   "metadata": {},
   "source": [
    "##### **Includes only test cases for now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "574c8326-9515-415a-bd5f-5ee689c6b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_path = '/N/slate/potem/data/derived/extracted_conversation_old/posters_control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d5d0c5cd-b6f6-4c5d-af44-3f7408a8bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tweets that poster have in IO dataset\n",
    "\n",
    "poster_path = config['POSTER_PATH']\n",
    "poster_alive_with_tweet_count_file = poster_path['poster_alive_with_tweet_count_file']\n",
    "ids = file_hp.read_file(poster_alive_with_tweet_count_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f7e30e1a-97a3-416c-85ca-14a62140a1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[200524435, '2012-07-31 12:57', 2]\""
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2af8e554-4503-4b7f-8e9b-268a1d5a5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control tweets for getting conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e6844ec6-3cf4-42c9-8243-c368afeb4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_control = config['POSTER_CONTROL']\n",
    "poster_control_info = poster_control['poster_control_info']\n",
    "\n",
    "poster_control_conv = poster_control_info + os.sep +'poster_control_conversation_1.txt'\n",
    "poster_control_user = poster_control_info + os.sep + 'poster_control_track_1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2d02b1e9-f431-40aa-be54-4f016768b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_user = file_hp.read_file(poster_control_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "237dad90-ec23-49c0-b29d-55cd97c7bcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['200524435', '74448776', '375186723', '337092191', '2674106707']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_user[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ff9b05d8-23c3-4744-9c8c-b740bbddb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_conv = file_hp.read_file(poster_control_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "80492d28-2b2d-46d0-82f6-cfeeb4c60d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['200524435', '74448776', '375186723', '337092191', '2674106707']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_conv[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece95c3e-ff7c-4bff-ad99-e915b0104b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole conversations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e42a4a10-8187-41ca-9a00-b386e2760865",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_control_path = config['POSTER_CONTROL']\n",
    "pc_extracted_conversations = poster_control_path['pc_extracted_conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aab192d5-14ca-4e06-9d8d-3baa5cd091d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b923ba4f-1f70-4373-a812-346a4a38203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   text                    100 non-null    object\n",
      " 1   conversation_id         100 non-null    object\n",
      " 2   lang                    100 non-null    object\n",
      " 3   entities                0 non-null      object\n",
      " 4   possibly_sensitive      100 non-null    bool  \n",
      " 5   reply_settings          100 non-null    object\n",
      " 6   created_at              100 non-null    object\n",
      " 7   edit_history_tweet_ids  100 non-null    object\n",
      " 8   tweetid                 100 non-null    object\n",
      " 9   author_id               100 non-null    object\n",
      " 10  retweet_count           100 non-null    int64 \n",
      " 11  reply_count             100 non-null    int64 \n",
      " 12  like_count              100 non-null    int64 \n",
      " 13  quote_count             100 non-null    int64 \n",
      " 14  impression_count        100 non-null    int64 \n",
      " 15  expanded_url            94 non-null     object\n",
      " 16  display_url             94 non-null     object\n",
      " 17  in_reply_to_user_id     0 non-null      object\n",
      " 18  referenced_tweets       16 non-null     object\n",
      " 19  context_annotations     1 non-null      object\n",
      " 20  entity_annotations      0 non-null      object\n",
      " 21  cashtags                0 non-null      object\n",
      " 22  hashtags                14 non-null     object\n",
      " 23  mentions                12 non-null     object\n",
      "dtypes: bool(1), int64(5), object(18)\n",
      "memory usage: 18.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "all_control_conversations = []\n",
    "all_sum = 0\n",
    "track = []\n",
    "for row in ids:\n",
    "    row = row.strip('][').split(', ')\n",
    "\n",
    "    user = int(row[0])\n",
    "    start_time = row[1]\n",
    "    count = int(row[2])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(user)\n",
    "    print(count)\n",
    "    poster_filename = f'control_tweets_{user}.jsonl'\n",
    "    new_path = os.path.join(poster_control_new_tweets, \n",
    "                            poster_filename)\n",
    "    isExist = os.path.exists(new_path)\n",
    "    \n",
    "    if isExist == False:\n",
    "        continue\n",
    "        \n",
    "    df = twitter_hp.parse_tweets(new_path)\n",
    "    print(df.info())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae643e-ec15-45ee-9348-75f902ede5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
