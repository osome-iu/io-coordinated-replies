{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e312ddf-64b8-42ae-825e-4b0d6f9bd000",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **This notebook gets the userid and tweet time of all replies**\n",
    "#### **that have greater 5 or more replies from IO accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ebdac5-b263-429d-b90f-1b6246fa26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltc\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "\n",
    "#### packages\n",
    "import helper.strategy_helper as st\n",
    "import helper.visualization as vz\n",
    "import helper.helper as hp\n",
    "import helper.file_helper as file_hp\n",
    "import config.config as config_hp\n",
    "import helper.pandas_helper as pd_hp\n",
    "import helper.twitter_helper as twitter_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6c324-6d88-4b6c-982d-cf4765fed8a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Read config files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b997578-da73-4966-9e03-0f53ceca2858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = config_hp.config()\n",
    "path = config['PATHS']\n",
    "\n",
    "derived_path = path['derived_path']\n",
    "all_tweet_data = path['all_tweet_data']\n",
    "plot_path = path['plot_path']\n",
    "external_reply = path['external_reply']\n",
    "conversation_ids_5 = path['conversation_ids_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e1773-833e-495c-8029-85e392a2bfab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Read files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d866c8-bbf5-4c7f-b177-8b59354aee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_campaigns, names = st.bundle_campaign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e074617-2323-4a7e-894c-c335e80ddbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies = pd.read_pickle(external_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce605c8-78f8-4809-94d7-f8bdf98de9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21427154 entries, 0 to 21427153\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   replier_tweetid  int64  \n",
      " 1   replier_userid   object \n",
      " 2   poster_tweetid   float64\n",
      " 3   poster_userid    float64\n",
      " 4   tweet_language   object \n",
      " 5   tweet_time       object \n",
      " 6   year             object \n",
      " 7   campaign         object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_replies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a7ab6f-367c-4cb8-beaa-97455e3fc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies = df_replies.astype({\n",
    "    'poster_tweetid': int,\n",
    "    'poster_userid': int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca8f790-95fb-4943-87bc-50679d532a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15256547"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replies['poster_tweetid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7559eb82-c0f5-4159-aaab-0c5bd582d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_5_conversation = file_hp.read_file(conversation_ids_5)\n",
    "\n",
    "all_5_conversation = [int(i) for i in all_5_conversation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8aaec3-aded-4d44-b717-6dbf16f6e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of type data:  <class 'list'>\n",
      "Total conversations : 96041\n",
      "Type of element : <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of type data: ', type(all_5_conversation))\n",
    "print('Total conversations :' , len(all_5_conversation))\n",
    "print('Type of element :', type(all_5_conversation[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02880c-77aa-4f08-8d24-4bc0e34b9407",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Getting all the tweets with 5 or more replies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11bd2ff5-3942-4260-a5ea-c26c7cc43b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv = df_replies.loc[\n",
    "    df_replies['poster_tweetid'].isin(all_5_conversation)][['poster_tweetid', 'poster_userid', 'tweet_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5c2936-c8f8-4ec9-886d-ea60f06fd60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1507927 entries, 973 to 21426755\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   poster_tweetid  1507927 non-null  int64 \n",
      " 1   poster_userid   1507927 non-null  int64 \n",
      " 2   tweet_time      1507927 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 46.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_conv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d1c0d00-0802-4514-9055-709270c3f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cov = df_conv.sort_values(by=['tweet_time'])\n",
    "\n",
    "df_cov['tweet_time'] = pd.to_datetime(df_cov['tweet_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90799d6f-d5c5-4511-b17c-4212ea24ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_last = pd_hp.read_first_last_row_of_grp(df_conv,\n",
    "                                                 'poster_tweetid',\n",
    "                                                 'tweet_time'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c1f774-af51-494f-8b36-30fc955b2700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poster_tweetid</th>\n",
       "      <th>poster_userid</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175649582045347840</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-02 18:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175649582045347840</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-02 18:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176283333385396224</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-03-04 13:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176283333385396224</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-03-04 13:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177373540574695424</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-07 12:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       poster_tweetid  poster_userid        tweet_time\n",
       "0  175649582045347840      131812518  2012-03-02 18:40\n",
       "1  175649582045347840      131812518  2012-03-02 18:44\n",
       "2  176283333385396224      200524435  2012-03-04 13:29\n",
       "3  176283333385396224      200524435  2012-03-04 13:59\n",
       "4  177373540574695424      131812518  2012-03-07 12:48"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b60364e3-5ad0-4075-b6a2-f7d65f27d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_last['last_reply'] = pd.to_datetime(\n",
    "    df_first_last['tweet_time']) + pd.Timedelta(24, unit='h') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17d27b0b-b6e4-473c-93eb-adf862c25992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poster_tweetid</th>\n",
       "      <th>poster_userid</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>last_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175649582045347840</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-02 18:40</td>\n",
       "      <td>2012-03-03 18:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175649582045347840</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-02 18:44</td>\n",
       "      <td>2012-03-03 18:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176283333385396224</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-03-04 13:29</td>\n",
       "      <td>2012-03-05 13:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176283333385396224</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-03-04 13:59</td>\n",
       "      <td>2012-03-05 13:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177373540574695424</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-07 12:48</td>\n",
       "      <td>2012-03-08 12:48:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       poster_tweetid  poster_userid        tweet_time          last_reply\n",
       "0  175649582045347840      131812518  2012-03-02 18:40 2012-03-03 18:40:00\n",
       "1  175649582045347840      131812518  2012-03-02 18:44 2012-03-03 18:44:00\n",
       "2  176283333385396224      200524435  2012-03-04 13:29 2012-03-05 13:29:00\n",
       "3  176283333385396224      200524435  2012-03-04 13:59 2012-03-05 13:59:00\n",
       "4  177373540574695424      131812518  2012-03-07 12:48 2012-03-08 12:48:00"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_last = df_first_last.sort_values(by=['tweet_time'])\n",
    "\n",
    "df_first_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8532751e-3af5-467a-82ef-956ce00ec009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grps = df_first_last.groupby('poster_tweetid').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84e38752-1e53-4368-bc13-4cde6db4d0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poster_tweetid</th>\n",
       "      <th>poster_userid</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>last_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175649582045347840</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-02 18:44</td>\n",
       "      <td>2012-03-03 18:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176283333385396224</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-03-04 13:59</td>\n",
       "      <td>2012-03-05 13:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>177373540574695424</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-03-07 13:19</td>\n",
       "      <td>2012-03-08 13:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>191443676885565440</td>\n",
       "      <td>131812518</td>\n",
       "      <td>2012-04-15 08:38</td>\n",
       "      <td>2012-04-16 08:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>230276901355286528</td>\n",
       "      <td>200524435</td>\n",
       "      <td>2012-07-31 12:44</td>\n",
       "      <td>2012-08-01 12:44:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       poster_tweetid  poster_userid        tweet_time          last_reply\n",
       "1  175649582045347840      131812518  2012-03-02 18:44 2012-03-03 18:44:00\n",
       "3  176283333385396224      200524435  2012-03-04 13:59 2012-03-05 13:59:00\n",
       "5  177373540574695424      131812518  2012-03-07 13:19 2012-03-08 13:19:00\n",
       "7  191443676885565440      131812518  2012-04-15 08:38 2012-04-16 08:38:00\n",
       "9  230276901355286528      200524435  2012-07-31 12:44 2012-08-01 12:44:00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2d783-b6f2-4a00-8a13-411af19ae4b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Save userid and tweet time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d4a152e-1d80-47f2-9028-d3dbb5f106bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hp.create_folder(derived_path, 'posters')\n",
    "user_path = os.path.join(derived_path, 'posters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b240ccb7-9b5d-4f16-a11f-1359631de085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/N/slate/potem/data/derived/posters'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "447b942e-8310-4494-b1e1-10539a2ca5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_reply_ids_path = path['splited_reply_ids']\n",
    "splited_reply_ids_path = os.path.join(splited_reply_ids_path, \n",
    "                                      '*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "915e32bf-d6b3-43d2-979a-e20f489a559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(splited_reply_ids_path):\n",
    "    parts = file.split('/')\n",
    "    index = parts[-1].split('_')[1]\n",
    "    \n",
    "    # if int(index) > 60:\n",
    "    #     continue\n",
    "        \n",
    "    ids = file_hp.read_file(file)\n",
    "\n",
    "    ids = [int(i) for i in ids]\n",
    "    \n",
    "    tweets = df_grps.loc[df_grps['poster_tweetid'].isin(ids)]\n",
    "    \n",
    "    rows = tweets['poster_userid']\n",
    "    start_time = tweets['tweet_time']\n",
    "    end_time = tweets['last_reply']\n",
    "    \n",
    "    file_hp.write_to_file_row_each_line(user_path,\n",
    "                                        'posters_' + parts[-1],\n",
    "                                        rows\n",
    "                                       )\n",
    "    file_hp.write_to_file_row_each_line(user_path,\n",
    "                                        'start_time_' + parts[-1],\n",
    "                                        start_time\n",
    "                                       )\n",
    "    \n",
    "    file_hp.write_to_file_row_each_line(user_path,\n",
    "                                         'end_time_' + parts[-1],\n",
    "                                        end_time\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d8dfdec-a02a-4029-853e-8e5926d57da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_hp.read_file(user_path + '/job_9_400_450.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2162c-d950-43df-80b7-169d2a60f4f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Get tweets from poster ids after reply (within in window of 24 hours)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66d5970a-a781-4d12-8817-06fcca14e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_path = os.path.join(derived_path, 'posters')\n",
    "poster_path = os.path.join(user_path, 'posters_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b706407c-ff18-4d63-952b-d979c07e0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_tweet_path = file_hp.create_folder(derived_path, \n",
    "                                          'posters_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abbd2f56-b7c3-4239-a5a1-19376d76d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3701207/158224794.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'helper.file_helper' from '/geode2/home/u070/potem/Quartz/project/infoOps-strategy/package/helper/file_helper.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "\n",
    "imp.reload(file_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "507a2b21-a80a-4417-982a-1bf45becdbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twarc2 timeline --start-time=2015-12-17T18:57:00 --end-time=2015-12-18T18:57:00  --use-search --exclude-retweets --exclude-replies 1933612350 > /N/slate/potem/data/derived/posters_tweets/job_34_1650_1700_1933612350.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Processed a day/a day [14:32<00:00, 2 tweets total ]    \n"
     ]
    }
   ],
   "source": [
    "for id_file in glob.glob(poster_path):\n",
    "    parts = id_file.split(os.sep)\n",
    "    index = parts[-1].split('_')[2]\n",
    "    filename = parts[-1].split('.')[0]\n",
    "    \n",
    "    if int(index) > 60:\n",
    "        continue\n",
    "        \n",
    "    start_time = filename.replace('posters', 'start_time') + '.txt'\n",
    "    end_time = filename.replace('posters', 'end_time') + '.txt'\n",
    "    campaign_json = f'{filename}.jsonl'\n",
    "    \n",
    "    path_to_json = os.path.join(poster_tweet_path, campaign_json)\n",
    "    start_time_file = os.path.join(user_path, start_time)\n",
    "    end_time_file =  os.path.join(user_path, end_time)\n",
    "    \n",
    "    start_file = file_hp.read_file(start_time_file)\n",
    "    end_file = file_hp.read_file(end_time_file)\n",
    "    posters = file_hp.read_file(id_file)\n",
    "    \n",
    "    for i, user in enumerate(posters):\n",
    "        job_info = filename.replace('posters_', '')\n",
    "        poster_filename = f'{job_info}_{user}.jsonl'\n",
    "        path = os.path.join(poster_tweet_path, poster_filename)\n",
    "        \n",
    "        start_file[i] = pd.to_datetime(start_file[i]) + pd.Timedelta(0, unit='s')\n",
    "        end_file[i] = pd.to_datetime(end_file[i]) + pd.Timedelta(0, unit='s')\n",
    "        \n",
    "        start_file[i] = start_file[i].isoformat('T')\n",
    "        end_file[i] = end_file[i].isoformat('T')\n",
    "        \n",
    "        command = f'twarc2 timeline --start-time={start_file[i]} ' \\\n",
    "        f' --sort-order=relevancy --use-search --exclude-retweets --exclude-replies ' \\\n",
    "        f'{user} > {path}'\n",
    "        \n",
    "        print(command)\n",
    "        \n",
    "        os.system(command)  \n",
    "        \n",
    "        break\n",
    "\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5401e-c16d-4060-b0eb-a1d472c8df67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Get profile metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77933b8f-c90c-46db-99e5-610cc6bcddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies = pd.read_pickle(external_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf6a3145-6e40-43d0-b2d3-d616c2416543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posters = df_replies.loc[df_replies['poster_tweetid'].isin(all_5_conversation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a63d3a-7d6f-4177-a254-6294f22d5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posters = df_posters.astype({\n",
    "    'poster_userid': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff865bda-e45f-4d28-b837-7c32fc157b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posters : 15016\n"
     ]
    }
   ],
   "source": [
    "poster_ids = list(df_posters['poster_userid'].unique())\n",
    "\n",
    "print('Total posters :', len(poster_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62b95d0-1d66-4516-a12e-952860153823",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster = config['POSTER_PATH']\n",
    "\n",
    "poster_path = poster['poster_info_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f45857ed-ce3b-4c5f-9342-c05f7e8733cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hp.write_to_file_row_each_line(poster_path, \n",
    "                                    'poster_userid.txt',\n",
    "                                    poster_ids, \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34864353-09c9-47cf-8be8-127cc08629a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_path = config['POSTER_PATH']\n",
    "poster_id_path = poster_path['poster_id_path']\n",
    "poster_json_path = poster_path['poster_json_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9a113f4-9828-46e8-9c7c-efdcd6dfe30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twarc2 users /N/slate/potem/data/derived/posters_info/poster_userid.txt /N/slate/potem/data/derived/posters/poster_info.jsonl\n"
     ]
    }
   ],
   "source": [
    "def get_profile_info(profile_id_file, \n",
    "                     profile_json_file):\n",
    "    '''\n",
    "    Gets the user meta data\n",
    "    :param profile_id_file: Twitter account userid file\n",
    "    :param profile_json_file: File path with file name for\n",
    "    json of profiles\n",
    "    '''\n",
    "    command = f'twarc2 users {profile_id_file} {profile_json_file}'\n",
    "    print(command)\n",
    "    os.system(command)  \n",
    "        \n",
    "        \n",
    "get_profile_info(poster_id_path, poster_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f7802-a67d-4c66-98c3-b14df145c146",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Parse the poster info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22512d9d-58ee-4770-b8df-6f0da30c8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_path = config['POSTER_PATH']\n",
    "\n",
    "poster_json_path = poster_path['poster_json_path']\n",
    "poster_id_path = poster_path['poster_id_path']\n",
    "poster_info_path = poster_path['poster_info_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac280a71-b28c-4e61-b3e4-a7cd262325c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of posters:  15016\n"
     ]
    }
   ],
   "source": [
    "def get_empty_profile_dict():\n",
    "    '''\n",
    "    Creates an empty variable to store profile information\n",
    "    '''\n",
    "    profiles = {\n",
    "        'created_at': None,\n",
    "        'verified': None,\n",
    "        'description': None,\n",
    "        'protected': None,\n",
    "        'username': None,\n",
    "        'id': None,\n",
    "        'proile_image_url': None,\n",
    "        'pinned_tweet_id': None,\n",
    "        'name': None,\n",
    "        'public_metrics': None,\n",
    "        'followers_count': None,\n",
    "        'following_count': None,\n",
    "        'tweet_count': None,\n",
    "        'listed_count': None\n",
    "    }\n",
    "    \n",
    "    return profiles\n",
    "\n",
    "\n",
    "def set_values_in_profile_dict(values):\n",
    "    '''\n",
    "    Sets variable values for profiles\n",
    "    :param dic_variable: empty dictionary variable\n",
    "    :param values: values from which values are to be stored\n",
    "    \n",
    "    :return dictionary\n",
    "    '''\n",
    "    profile = get_empty_profile_dict()\n",
    "    profile['created_at']=values['created_at']\n",
    "    profile['verified']=values['verified']\n",
    "    profile['description']=values['description']\n",
    "    profile['protected']=values['protected']\n",
    "    profile['username']=values['username']\n",
    "    profile['id']=values['id']\n",
    "    profile['profile_image_url']=values['profile_image_url']\n",
    "\n",
    "    if 'pinned_tweet_id' in values:\n",
    "        profile['pinned_tweet_id']=values['pinned_tweet_id']\n",
    "\n",
    "    profile['name']=values['name']\n",
    "\n",
    "    if 'public_metrics' in values:\n",
    "        public_metrics = values['public_metrics']\n",
    "        profile['followers_count']=public_metrics['followers_count']\n",
    "        profile['following_count']=public_metrics['following_count']\n",
    "        profile['tweet_count']=public_metrics['tweet_count']\n",
    "        profile['listed_count']=public_metrics['listed_count']\n",
    "        \n",
    "    return profile\n",
    "\n",
    "\n",
    "\n",
    "def set_values_for_profile_error(values):\n",
    "    '''\n",
    "    Sets variable values for profiles which are not available\n",
    "    :param values: values to be stored\n",
    "    \n",
    "    :return dictionary\n",
    "    '''\n",
    "    if values['resource_type'] != 'user':\n",
    "        return None\n",
    "    \n",
    "    profile = get_empty_profile_dict()\n",
    "    \n",
    "    if 'suspended' in values['detail']:\n",
    "        profile['verified'] = 'suspended'\n",
    "    if 'not find user' in values['detail']:\n",
    "        profile['verified'] = 'not found'\n",
    "        \n",
    "    profile['description'] = values['detail']\n",
    "    profile['id'] = values['value']\n",
    "    \n",
    "    return profile\n",
    "\n",
    "\n",
    "\n",
    "def parse_profile_json(profile_file, \n",
    "                       output_file=None) -> pd.DataFrame:\n",
    "    '''\n",
    "    Parse the profile json file\n",
    "    \n",
    "    :param profile_file: location (along with file name)\n",
    "    to the profile json file\n",
    "    :param output_file: location (along with file name) to save\n",
    "    the parsed file\n",
    "    \n",
    "    :return DataFrame\n",
    "    '''\n",
    "    \n",
    "    all_profiles = []\n",
    "    \n",
    "    with open(profile_file, 'r') as json_file:\n",
    "        for row in json_file:\n",
    "            one_row = json.loads(row)\n",
    "            # print(one_row.keys())\n",
    "            # print(one_row['errors'])\n",
    "            \n",
    "            if 'errors' in one_row:\n",
    "                for single_profile in one_row['errors']:\n",
    "                    profile = set_values_for_profile_error(single_profile)\n",
    "                    \n",
    "                    if profile != None:\n",
    "                        all_profiles.append(profile)\n",
    "\n",
    "            if 'data' not in one_row:\n",
    "                continue\n",
    "                \n",
    "            for single_profile in one_row['data']:\n",
    "                profile = set_values_in_profile_dict(single_profile)\n",
    "                \n",
    "                if profile != None:\n",
    "                    all_profiles.append(profile)\n",
    "                \n",
    "    \n",
    "    df = pd.DataFrame.from_records(data=all_profiles)\n",
    "    \n",
    "    if output_file is not None:\n",
    "        df.to_pickle(output_file)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "poster_info_file = os.path.join(poster_info_path, \n",
    "                                'profile_info.pkl.gz')\n",
    "df_profiles = parse_profile_json(poster_json_path, \n",
    "                                 poster_info_file)\n",
    "\n",
    "print('Original number of posters: ', \n",
    "      len(file_hp.read_file(poster_id_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd185e37-43b7-4a46-a286-dd2bf4b6a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_found = df_profiles.loc[df_profiles['verified'] == 'not found']\n",
    "df_suspended = df_profiles.loc[df_profiles['verified'] == 'suspended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d993c97-7b3e-48ea-bd88-95dd27c5ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total not found accounts, :  3992\n",
      "Total suspended accounts, :  5041\n"
     ]
    }
   ],
   "source": [
    "print('Total not found accounts, : ', len(df_not_found))\n",
    "print('Total suspended accounts, : ', len(df_suspended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "759f293f-6717-4051-9e37-00599b429085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/N/slate/potem/data/derived/posters_info/profile_info.pkl.gz'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_info_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c58c4b-a54f-4148-bf35-c880eb8a0c27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Remove dead posters from control files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d5714a-c352-4740-9a64-99205c6dab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_hp.config()\n",
    "poster_control = config['POSTER_CONTROL']\n",
    "poster_control_path = poster_control['poster_control']\n",
    "\n",
    "poster = config['POSTER_PATH']\n",
    "poster_dead_tweet_file = poster['poster_dead_tweet_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39e682e3-f7d9-400a-b179-ced3585125ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dead_poster(path, org_rows):\n",
    "    '''\n",
    "    Remove rows from multiple file\n",
    "    :param path: path to files with filename wild cards\n",
    "    :param org_rows: original row list without unwanted rows\n",
    "    '''\n",
    "    for file in glob.glob(path):\n",
    "        print(file)\n",
    "        \n",
    "        start_time_file_name = file.replace('posters_','start_time_')\n",
    "        start_time_file = file_hp.read_file(start_time_file_name)\n",
    "        \n",
    "        ids = file_hp.read_file(file)\n",
    "        \n",
    "        if len(ids) <= len(start_time_file):\n",
    "            continue\n",
    "            \n",
    "        for i, row in enumerate(ids):\n",
    "            if row not in org_rows:\n",
    "                ids.remove(str(row))\n",
    "                start_time_file.pop(i)\n",
    "                \n",
    "        temp_file = open(f'{file}', 'r+')\n",
    "        \n",
    "        temp_file.truncate(0)\n",
    "        \n",
    "        file_hp.write_to_file_row_each_line(file, \n",
    "                                    None, \n",
    "                                    ids)\n",
    "        temp_file = open(f'{start_time_file_name}', 'r+')\n",
    "        \n",
    "        temp_file.truncate(0)\n",
    "        \n",
    "        file_hp.write_to_file_row_each_line(start_time_file_name, \n",
    "                                            None, \n",
    "                                            ids)\n",
    "        \n",
    "# org_rows = file_hp.read_file(poster_dead_tweet_file)\n",
    "\n",
    "# remove_dead_poster(poster_control_path + os.sep + 'posters*.txt',\n",
    "#                    org_rows\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a868d8ea-3a7e-467f-8a6a-59907cf85010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_files(path):\n",
    "    '''\n",
    "    Checks the number of ids in txt files\n",
    "    :param path: Path of files\n",
    "    '''\n",
    "    for file in glob.glob(path):\n",
    "        ids = set(file_hp.read_file(file))\n",
    "        \n",
    "        if len(ids) == 0:\n",
    "            print(file, len(ids))\n",
    "        \n",
    "id_path = poster_control_path + os.sep + 'posters*.txt'\n",
    "\n",
    "remove_empty_files(id_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca0655-0d79-4d27-a623-8aa7c30ea256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Correcting the time to get the control tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2d19e7-f132-4a32-bda0-398402a298ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## posters folder has poster ids, start time and end time\n",
    "## posters_tweets has tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65dbccbe-59b4-432a-a93d-9f7e0a3e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "imp.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "path =  config['PATHS']\n",
    "poster = config['POSTER_PATH']\n",
    "poster_control_ids = config['POSTER_CONTROL']\n",
    "\n",
    "external_reply = path['external_reply']\n",
    "conversation_ids_5 = path['conversation_ids_5']\n",
    "poster_alive_file = poster['poster_alive_file']\n",
    "poster_alive_with_tweet_count_file = poster['poster_alive_with_tweet_count_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce5b971-e189-4a7b-a6b8-e8a0b49048ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_external_replies = pd.read_pickle(external_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1cc76f-7a92-4188-8e57-028b81a94b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21427154 entries, 0 to 21427153\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   replier_tweetid  int64  \n",
      " 1   replier_userid   object \n",
      " 2   poster_tweetid   float64\n",
      " 3   poster_userid    float64\n",
      " 4   tweet_language   object \n",
      " 5   tweet_time       object \n",
      " 6   year             object \n",
      " 7   campaign         object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_external_replies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c0d458-4233-4846-bc13-089e39845c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type :  <class 'str'>\n",
      "Number of datapoints : 96041\n",
      "Example id:  64953578015571968\n"
     ]
    }
   ],
   "source": [
    "ids = file_hp.read_file(conversation_ids_5)\n",
    "\n",
    "print('Type : ', type(ids[0]))\n",
    "print('Number of datapoints :', len(ids))\n",
    "print('Example id: ', ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046096cd-1871-48d4-af5d-6abd523ccbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_external_replies = df_external_replies.astype({\n",
    "    'poster_tweetid': int,\n",
    "})\n",
    "    \n",
    "df_external_replies = df_external_replies.astype({\n",
    "    'poster_tweetid': str,\n",
    "    'poster_userid': int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e39fc76-ef2f-4a2a-ace9-a63ff61904a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_external_replies['poster_tweetid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60111919-6b28-4de7-9235-0d5a94d6061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507927\n"
     ]
    }
   ],
   "source": [
    "df_5 = df_external_replies.loc[\n",
    "    df_external_replies['poster_tweetid'].isin(ids)]\n",
    "\n",
    "print(len(df_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1753e881-47df-4510-a907-b997c32c53e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15016"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5['poster_userid'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7906e-f69b-4768-80b6-21c90a252b04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Getting tweets size for each posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d46e981-1e8f-4cb2-b8f4-9d341b7f3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poster_tweets = (df_5.groupby(['poster_userid'])['poster_tweetid']\n",
    "                   .nunique()\n",
    "                   .to_frame('count')\n",
    "                   .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab373faf-6c92-4e6d-9692-55d98689e02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poster_tweets['count'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f9edde-985f-427a-84cf-b43a14ddcb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['poster_userid', 'count'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poster_tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a28cd-2066-4c9b-a63d-af34d71b7a47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Getting last tweet and tweet time for each poster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be20aae-d25a-453e-920d-0a468d600c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_5.sort_values(by=['tweet_time'],\n",
    "                        ascending=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "961ef8bc-7184-4ad9-bc88-0100062a82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poster_last_tweet = (df_5.groupby(['poster_userid'])[['poster_userid',\n",
    "                                                         'poster_tweetid', \n",
    "                                                         'tweet_time']]\n",
    "                        .tail(1)\n",
    "                        .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a749c2-4fbc-4e72-b21d-9e50b7bd7760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Keeping just alive posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e46fcc-9991-4a8c-a9ab-84bf8e77e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alive_posters = file_hp.read_file(poster_alive_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1004914-b32a-41e6-8feb-29dd5b0eafc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(alive_posters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac6f9f95-74b6-4051-b500-ec00ae396eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5983"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alive_posters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc53842-88c7-48d4-9e58-160dca832285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poster_last_tweet = df_poster_last_tweet.astype({\n",
    "    'poster_userid': str\n",
    "})\n",
    "df_poster_tweets = df_poster_tweets.astype({\n",
    "    'poster_userid': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da31deab-e0f4-4bc1-b821-bdb53218e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poster_last_tweet = df_poster_last_tweet.loc[\n",
    "    df_poster_last_tweet['poster_userid'].isin(alive_posters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9270b31-b55f-411c-82f2-1ecb2b501271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poster_tweets = df_poster_tweets.loc[\n",
    "    df_poster_tweets['poster_userid'].isin(alive_posters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce29f00f-dd39-4e7b-84ed-307ecb63856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5983\n",
      "5983\n"
     ]
    }
   ],
   "source": [
    "print(len(df_poster_last_tweet))\n",
    "print(len(df_poster_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e8675-f912-4b62-9420-c42a15329685",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Save alive posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d3d33df-92bc-4877-bee1-1d11fc2d0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = df_poster_last_tweet.merge(df_poster_tweets,\n",
    "                           on='poster_userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "520d7149-b62a-49d3-92cf-d6b7eba25172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = df_size.astype({\n",
    "    # 'poster_tweetid': str,\n",
    "    'poster_userid': int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a61782c-c02f-4bda-b5af-0c63dc99b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = df_size[\n",
    "    ['poster_userid', 'tweet_time', 'count']\n",
    "].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63d96563-99dc-4703-bdec-91059599648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200524435, '2012-07-31 12:57', 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c79fc37-5d4d-4b58-8352-7c318d0dd6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5983"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41324aa4-3134-4022-97eb-74a6cbdbb40a",
   "metadata": {},
   "source": [
    "##### **Save three information in file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045690ee-7927-4406-8e9b-2edd27a01598",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hp.write_to_file_row_each_line(poster_alive_with_tweet_count_file,\n",
    "                                    None,\n",
    "                                    data_list\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c350e31-57d1-4ce6-9437-efa2edd54e9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Get poster tweets after removing alive posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb3fa4aa-9c0d-4ee3-8a87-7afe8d69d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "imp.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "poster = config['POSTER_PATH']\n",
    "poster_alive_file = poster['poster_alive_file']\n",
    "poster_alive_with_tweet_count_file = poster['poster_alive_with_tweet_count_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f9f60-23f0-4d7a-bcc2-ec41d62763fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poster_tweets_with_count(config):\n",
    "    '''\n",
    "    Gets the poster tweets\n",
    "    :param config: config file to be loaded\n",
    "    '''\n",
    "    \n",
    "    config = config.config()\n",
    "    poster = config['POSTER_PATH']\n",
    "    poster_alive_with_tweet_count_file = poster['poster_alive_with_tweet_count_file']\n",
    "    \n",
    "    poster_control = config['POSTER_CONTROL']\n",
    "    poster_control_tweets = poster_control['poster_control_tweets']\n",
    "    poster_tweet_path = file_hp.create_folder(poster_control_tweets, \n",
    "                                              'posters_new_tweets')\n",
    "    poster_ids = file_hp.read_file(poster_alive_with_tweet_count_file)\n",
    "    \n",
    "    for row in poster_ids:\n",
    "        row = row.strip('][').split(', ')\n",
    "\n",
    "        user = int(row[0])\n",
    "        start_time = row[1]\n",
    "        count = row[2]\n",
    "        poster_filename = f'control_tweets_{user}.jsonl'\n",
    "        path = os.path.join(poster_tweet_path, poster_filename)\n",
    "\n",
    "        start_time = pd.to_datetime(start_time) + pd.Timedelta(0, unit='s')\n",
    "        start_time = start_time.isoformat('T')\n",
    "\n",
    "        command = f'twarc2 timeline --start-time={start_time} ' \\\n",
    "        f' --sort-order=relevancy --use-search --exclude-retweets --exclude-replies ' \\\n",
    "        f'--limit {count} {user} > {path}'\n",
    "\n",
    "        os.system(command)\n",
    "\n",
    "# \n",
    "# get_poster_tweets_with_count(config_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537e373-59ab-4308-a43f-c25db17a98a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Parse the control tweets from posters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6c17d8-df6c-412d-9705-2c3ae8bad6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "imp.reload(config_hp)\n",
    "imp.reload(twitter_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "poster = config['POSTER_PATH']\n",
    "poster_control = config['POSTER_CONTROL']\n",
    "\n",
    "poster_alive_file = poster['poster_alive_file']\n",
    "poster_alive_with_tweet_count_file = poster['poster_alive_with_tweet_count_file']\n",
    "\n",
    "poster_control_new_tweets = poster_control['poster_control_new_tweets']\n",
    "poster_control_info = poster_control['poster_control_info']\n",
    "# poster_control_conversations = poster_control['poster_control_conversations']\n",
    "pc_split_conversation_id = poster_control['pc_split_conversation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d84391-5d25-4afe-ab13-7d90e62d59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_posters = file_hp.read_file(poster_alive_with_tweet_count_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d46e75-68bf-4557-a217-82b19f03ad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6617\n",
      "3167\n",
      "6617\n"
     ]
    }
   ],
   "source": [
    "all_control_conversations = []\n",
    "all_sum = 0\n",
    "track = []\n",
    "for row in control_posters:\n",
    "    row = row.strip('][').split(', ')\n",
    "\n",
    "    user = int(row[0])\n",
    "    start_time = row[1]\n",
    "    count = int(row[2])\n",
    "    \n",
    "    if count == 0:\n",
    "        print(user)\n",
    "        \n",
    "    poster_filename = f'control_tweets_{user}.jsonl'\n",
    "    new_path = os.path.join(poster_control_new_tweets, \n",
    "                            poster_filename)\n",
    "    isExist = os.path.exists(new_path)\n",
    "    \n",
    "    if isExist == False:\n",
    "        continue\n",
    "        \n",
    "    df = twitter_hp.parse_tweets(new_path)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    \n",
    "    if count <= df['tweetid'].nunique():\n",
    "        all_sum = all_sum + count\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        df = df.sort_values(by=['created_at'],\n",
    "                        ascending=True\n",
    "                       )\n",
    "        top_count = df['tweetid'].head(count).tolist()\n",
    "        \n",
    "        track.append(user)\n",
    "        all_control_conversations.extend(top_count)\n",
    "\n",
    "print(all_sum)\n",
    "print(len(track))\n",
    "print(len(all_control_conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a10eee-3793-4a68-ad4a-ac9d5249a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hp.write_to_file_row_each_line(poster_control_info,\n",
    "                                    'poster_control_track_1.txt',\n",
    "                                    track\n",
    "                                   )\n",
    "file_hp.write_to_file_row_each_line(poster_control_info,\n",
    "                                    'poster_control_conversation_1.txt',\n",
    "                                    all_control_conversations\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf16b6-1adb-47ac-9f51-3862ad3b8349",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Split conversation ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd0ea6e-7d22-41c7-8aaf-a7f36313749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_path = os.path.join(poster_control_info,\n",
    "                                    'poster_control_conversation_1.txt'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b71e71-41fe-4a08-a472-1feb90b12579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_files(input_file, \n",
    "                     save_path,\n",
    "                     split_threshold=50,\n",
    "                     prefix_for_file='job_control_conversations'\n",
    "                    ):\n",
    "    '''\n",
    "    Splits the rows of file into multiple files\n",
    "    :param input_file: text file which has data\n",
    "    :param split_threshold: threshold to split the rows by\n",
    "    :param save_path: path where files are to be saved\n",
    "    :param prefix_for_file: prefix for new file names\n",
    "    '''\n",
    "    \n",
    "    rows = file_hp.read_file(input_file)\n",
    "    index = 1\n",
    "    for i in range(0, len(rows), split_threshold):\n",
    "        ids_split = rows[i:i+split_threshold]\n",
    "        last = i + split_threshold\n",
    "\n",
    "        #first is the index of job\n",
    "        #second and third are the index of rows\n",
    "        filename = f'{prefix_for_file}_{index}_{i}_{last}.txt'\n",
    "\n",
    "        file_hp.write_to_file_row_each_line(save_path,\n",
    "                                            filename,\n",
    "                                            ids_split\n",
    "                                           )\n",
    "\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a275a1f2-e19d-4845-a922-fb16fd37e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_into_files(conversation_path,\n",
    "                 pc_split_conversation_id,\n",
    "                 split_threshold=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a9147-1557-4102-bf4e-49e957b16c51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Create jobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba8bde0-c441-4959-95a0-dad8fdf6c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import helper.slurm_helper as slurm_hp\n",
    "\n",
    "imp.reload(config_hp)\n",
    "imp.reload(twitter_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "poster_control = config['POSTER_CONTROL']\n",
    "\n",
    "pc_split_conversation_id = poster_control['pc_split_conversation_id']\n",
    "pc_extracted_conversations = poster_control['pc_extracted_conversations']\n",
    "\n",
    "slurm_config = config['SLURM_PATH']\n",
    "slurm_path = slurm_config['slurm_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed35b217-0f88-45f5-9b1b-ad9741af30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm_script_path = file_hp.create_folder(slurm_path, \n",
    "                                          'control_conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d752666-e85b-4c2f-b0e3-df88cae2b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_jobs(multiple_file_path,\n",
    "                         python_script,\n",
    "                         path_slurm,\n",
    "                         destination_folder,\n",
    "                         logs_path=None\n",
    "               ):\n",
    "    '''\n",
    "    Path of splited conversations\n",
    "    :param multiple_file_path: path where multiple files are present\n",
    "    :param python_script: script to be run\n",
    "    :param path_slurm: path where slurm script to be saved\n",
    "    :param destination_folder: folder where the data is to be saved\n",
    "    :param logs_path: path where log file are to be saved\n",
    "    '''\n",
    "    new_path = os.path.join(multiple_file_path, f'job_control_*.txt')\n",
    "    i = 0\n",
    "    \n",
    "    if logs_path == None:\n",
    "        file_hp.create_folder(path_slurm, 'logs')\n",
    "        logs_path = os.path.join(path_slurm, 'logs')\n",
    "        \n",
    "    for file in glob.glob(new_path):\n",
    "        i = i + 1\n",
    "        parts = file.split(os.sep)\n",
    "        filename = (parts[-1]).split('.')[0]\n",
    "        command = f'python {python_script} --file={file} ' + \\\n",
    "        f'--destination-folder={destination_folder}'\n",
    "        \n",
    "        job_name = f'{filename}'\n",
    "        slurm_scrip_path = slurm_hp.create_slurm_script(job_name, \n",
    "                                     command,\n",
    "                                     path_slurm)\n",
    "        print(slurm_scrip_path)\n",
    "        \n",
    "        \n",
    "        slurm_hp.despatch_single_job(slurm_scrip_path,\n",
    "                                     logs_path\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "# script_path = '/N/u/potem/Quartz/project/infoOps-strategy/script/py_scripts/data_sourcing/get_conversation.py'\n",
    "# create_multiple_jobs(pc_split_conversation_id, \n",
    "#                      script_path,\n",
    "#                      slurm_script_path,\n",
    "#                      pc_extracted_conversations\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a162c1ec-8ba7-476d-87ba-5fc48ceebda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def despatch_job(path, logs_path):\n",
    "    \n",
    "    for file in glob.glob(path):\n",
    "        job_index = file.split('/')[-1].split('_')[3]\n",
    "        # print(file)\n",
    "        if int(job_index) > 100:\n",
    "            continue\n",
    "            \n",
    "        command = f'sbatch {file}'\n",
    "        \n",
    "        os.chdir(logs_path)\n",
    "        os.system(command)\n",
    "        print(job_index)\n",
    "\n",
    "        \n",
    "slurm_path_og='/N/u/potem/Quartz/sbatch'\n",
    "slurm_path = os.path.join(slurm_path_og, \n",
    "                        'control_conversations')\n",
    "file_hp.create_folder(slurm_path, 'logs')\n",
    "logs_path = file_hp.create_folder(slurm_path, 'logs')\n",
    "new_path = os.path.join(slurm_path, f'*.sh')\n",
    "\n",
    "## Do not forget to change get_conversation file\n",
    "# despatch_job(new_path, logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d502cebe-ca4d-444d-857f-040508a0fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_jobs(start_no, end_no):\n",
    "    '''\n",
    "    Cancels the jobs\n",
    "    :param start_no: starting job no\n",
    "    :param end_no: ending job no\n",
    "    '''\n",
    "    print('here')\n",
    "    for i in range(start_no, end_no+1):\n",
    "        # id = start_no + i\n",
    "        print(i)\n",
    "        command = f'scancel {i}'\n",
    "\n",
    "        os.system(command)\n",
    "        \n",
    "        \n",
    "# cancel_jobs(1474611, 1474711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f627a7e6-8828-42db-b7a9-705445af4783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474711"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1474611+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221b159-6801-415c-802d-960d64115ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
