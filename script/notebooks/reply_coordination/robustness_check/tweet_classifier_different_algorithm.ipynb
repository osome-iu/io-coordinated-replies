{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635962d3-39cc-4ec9-ab97-1ad7154d0169",
   "metadata": {},
   "source": [
    "#### **This notebook test for different algorithm results for tweet classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16f81fc-22da-4acd-a836-69718dfbb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "#### packages\n",
    "import helper.strategy_helper as st\n",
    "import helper.visualization as viz_hp\n",
    "import config.config as config_hp\n",
    "import matplotlib.pyplot as plt\n",
    "import helper.stat_helper as stat_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185afe94-aece-4d9f-9a47-3ef5c1d91f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stat_hp)\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "stat = config['STATS']\n",
    "\n",
    "final_stat = stat['final_stat']\n",
    "\n",
    "df_all_stat = pd.read_pickle(final_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16965308-1650-4d13-8382-4de319b4f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def run_model(df,\n",
    "              columns_not_include=['list_age'],\n",
    "              model_type='random', \n",
    "              y_column = 'tweet_label',\n",
    "              filename=None,\n",
    "             ):\n",
    "    '''\n",
    "    Trains the model and prints the result\n",
    "    :param df: Dataframe\n",
    "    :param model_type: Type of model\n",
    "    :param pca: Whether to do PCA or not\n",
    "    :param columns_not_include: columns to not include\n",
    "    '''\n",
    "    print(f'\\n **** {model_type} ****')\n",
    "    \n",
    "    ### Remove unnecessary columns\n",
    "    import pickle\n",
    "\n",
    "    model_filename = filename\n",
    "    \n",
    "    columns_not_include.extend(\n",
    "        ['poster_tweetid','tweet_label', 'replier_userid', 'replier_label'])\n",
    "    \n",
    "    columns_to_keep = list(set(df.columns) - set(columns_not_include))\n",
    "\n",
    "    X = df[columns_to_keep]\n",
    "    y = df[y_column]\n",
    "  \n",
    "    ### Choose model\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(random_state=0)\n",
    "    elif model_type == 'random':\n",
    "        print('Running Random Forest')\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                   random_state=42\n",
    "                                  )\n",
    "    elif model_type == 'ada':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier(n_estimators=100,\n",
    "                                 algorithm=\"SAMME\", random_state=0)\n",
    "    elif model_type == 'tree':\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    elif model_type == 'naive':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "    \n",
    "    ### Choose scoring function\n",
    "    from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "    # Creating a dictionary of scorers\n",
    "    scoring = {\n",
    "        'precision': make_scorer(precision_score, average='binary'),\n",
    "        'recall': make_scorer(recall_score, average='binary'),\n",
    "        'f1': make_scorer(f1_score, average='binary'),\n",
    "        'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n",
    "    }\n",
    "\n",
    "    cv_scores = [\n",
    "        \"train_precision\",\n",
    "        \"test_precision\",\n",
    "        \"train_recall\",\n",
    "        \"test_recall\",\n",
    "        \"train_f1\",\n",
    "        \"test_f1\",\n",
    "        \"train_roc_auc\",\n",
    "        \"test_roc_auc\",\n",
    "    ]\n",
    "\n",
    "    from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    model = make_pipeline(StandardScaler(), model)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    tuned_model = TunedThresholdClassifierCV(estimator=model,\n",
    "                                             scoring='f1',\n",
    "                                             store_cv_results = True,\n",
    "                                             n_jobs=-1\n",
    "                                            )\n",
    "\n",
    "    cv_results_tuned_model = pd.DataFrame(\n",
    "        cross_validate(\n",
    "            tuned_model,\n",
    "            X,\n",
    "            y,\n",
    "            scoring=scoring,\n",
    "            cv=cv,\n",
    "            return_train_score=True,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "    )\n",
    "   \n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    decision_threshold = pd.Series(\n",
    "        [est.best_threshold_ for est in cv_results_tuned_model[\"estimator\"]],\n",
    "    )\n",
    "    cv_results_tuned_model['threshold'] = decision_threshold\n",
    "    \n",
    "    cv_results_tuned_model['algorithm'] = model_type\n",
    "    \n",
    "    return cv_results_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35db96ff-5e91-40c1-8819-50fa71dbce5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7b94dc-611d-4a91-8ce6-c1210877fb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run_model(df_all_stat,\n",
    "#           columns_not_include=[],\n",
    "#           model_type='logistic', \n",
    "#           pca=False,\n",
    "#           y_column = 'tweet_label',\n",
    "#           filename=None,\n",
    "#          just_f1=False,\n",
    "#          find_threshold=False\n",
    "#          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05233a-c601-4bbd-8d6c-442aed707f86",
   "metadata": {},
   "source": [
    "#### **Run for all algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbfbde-2acf-4de8-9f24-8fd48a968d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algorithms = ['logistic', 'ada', 'random', 'tree', 'naive']\n",
    "all_results = []\n",
    "for algo in algorithms:\n",
    "    df_result = run_model(df_all_stat,\n",
    "                   columns_not_include=['list_age'],\n",
    "                   model_type=algo, \n",
    "                   y_column = 'tweet_label',\n",
    "                   filename=None,\n",
    "                  )\n",
    "    \n",
    "    all_results.append(df_result)\n",
    "    \n",
    "(pd.concat(all_results, ignore_index=True)\n",
    ").to_pickle('./data/tweet_classifier_different_algorithm.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff25b101-d715-4835-88e4-9f009ad3c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_pickle(\n",
    "    './data/tweet_classifier_different_algorithm.pkl.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eb9635b-17e8-4a02-8fef-5f3161f9b9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2342333/389040144.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_result.loc[df_result['algorithm'] == 'logistic'].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fit_time           0.812179\n",
       "score_time         0.010199\n",
       "test_precision     0.657619\n",
       "train_precision    0.662751\n",
       "test_recall        0.862572\n",
       "train_recall       0.869936\n",
       "test_f1            0.745949\n",
       "train_f1           0.752084\n",
       "test_roc_auc       0.803156\n",
       "train_roc_auc      0.814571\n",
       "threshold          0.353939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.loc[df_result['algorithm'] == 'logistic'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a41a7a6-d292-41ec-b711-825577d79a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2342333/3179702392.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .mean()\n"
     ]
    }
   ],
   "source": [
    "df_grp = (df_result\n",
    "          .groupby(['algorithm'])\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          .sort_values(by='test_roc_auc',\n",
    "                       ascending=False\n",
    "                      )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31a576af-8eb9-483c-98d2-3f9a61c00475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['algorithm', 'fit_time', 'score_time', 'test_precision',\n",
       "       'train_precision', 'test_recall', 'train_recall', 'test_f1', 'train_f1',\n",
       "       'test_roc_auc', 'train_roc_auc', 'threshold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e3007cc-67e7-4c3d-ae2d-4f801c18fce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorith : random\n",
      "test_precision    0.738555\n",
      "test_recall       0.878118\n",
      "test_f1           0.801964\n",
      "test_roc_auc      0.884198\n",
      "Name: 3, dtype: object\n",
      "*************** \n",
      "\n",
      "Algorith : ada\n",
      "test_precision    0.646652\n",
      "test_recall       0.891828\n",
      "test_f1           0.749283\n",
      "test_roc_auc      0.812638\n",
      "Name: 0, dtype: object\n",
      "*************** \n",
      "\n",
      "Algorith : logistic\n",
      "test_precision    0.657619\n",
      "test_recall       0.862572\n",
      "test_f1           0.745949\n",
      "test_roc_auc      0.803156\n",
      "Name: 1, dtype: object\n",
      "*************** \n",
      "\n",
      "Algorith : tree\n",
      "test_precision    0.522464\n",
      "test_recall       0.956309\n",
      "test_f1           0.665887\n",
      "test_roc_auc      0.699343\n",
      "Name: 4, dtype: object\n",
      "*************** \n",
      "\n",
      "Algorith : naive\n",
      "test_precision    0.494626\n",
      "test_recall            1.0\n",
      "test_f1           0.661873\n",
      "test_roc_auc      0.685112\n",
      "Name: 2, dtype: object\n",
      "*************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, df_row in df_grp.iterrows():\n",
    "    print('Algorith :', df_row['algorithm'])\n",
    "    print(df_row[['test_precision', 'test_recall', 'test_f1', 'test_roc_auc']])\n",
    "    print('*************** \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69264f36-f00c-4eb5-aba6-adec0d768de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
