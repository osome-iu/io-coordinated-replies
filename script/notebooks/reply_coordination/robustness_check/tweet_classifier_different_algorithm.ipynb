{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635962d3-39cc-4ec9-ab97-1ad7154d0169",
   "metadata": {},
   "source": [
    "#### **This notebook test for different algorithm results for tweet classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16f81fc-22da-4acd-a836-69718dfbb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "\n",
    "#### packages\n",
    "import helper.strategy_helper as st\n",
    "import helper.visualization as viz_hp\n",
    "import config.config as config_hp\n",
    "import matplotlib.pyplot as plt\n",
    "import helper.stat_helper as stat_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185afe94-aece-4d9f-9a47-3ef5c1d91f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(stat_hp)\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "stat = config['STATS']\n",
    "\n",
    "final_stat = stat['final_stat']\n",
    "\n",
    "df_all_stat = pd.read_pickle(final_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16965308-1650-4d13-8382-4de319b4f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def run_model(df,\n",
    "              columns_not_include=['list_age'],\n",
    "              model_type='random', \n",
    "              pca=False,\n",
    "              y_column = 'tweet_label',\n",
    "              filename=None,\n",
    "              just_f1=False,\n",
    "              find_threshold=True\n",
    "             ):\n",
    "    '''\n",
    "    Trains the model and prints the result\n",
    "    :param df: Dataframe\n",
    "    :param model_type: Type of model\n",
    "    :param pca: Whether to do PCA or not\n",
    "    :param columns_not_include: columns to not include\n",
    "    '''\n",
    "    print(f'\\n **** {model_type} ****')\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    model_filename =' k' #'user_classifier_without_pca_ran.sav'\n",
    "    \n",
    "    columns_not_include.extend(\n",
    "        ['poster_tweetid','tweet_label', 'replier_userid', 'replier_label'])\n",
    "    \n",
    "    columns_to_keep = list(set(df.columns) - set(columns_not_include))\n",
    "\n",
    "    X = df[columns_to_keep]\n",
    "    y = df[y_column]\n",
    "  \n",
    "    if 'mean_tensor' in columns_to_keep:\n",
    "        t = df['mean_tensor'].tolist()\n",
    "        t = torch.stack(t)\n",
    "        t = t[:, :100]\n",
    "        \n",
    "        columns_to_keep.remove('mean_tensor')\n",
    "        \n",
    "        z = df[columns_to_keep]\n",
    "        k = torch.tensor(z.values)\n",
    "        X = torch.cat((t, k), dim=1)\n",
    "    else:\n",
    "        print(df[y_column].unique())\n",
    "        X = df[columns_to_keep]\n",
    "        \n",
    "    #PCA \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    indices = df.index\n",
    "    \n",
    "    if pca == True:\n",
    "        print('here')\n",
    "        print(len(columns_to_keep))\n",
    "        pca = PCA()\n",
    "\n",
    "        # Fit the PCA object to the data and transform the data\n",
    "        X = pca.fit_transform(X)\n",
    "        print('After PCA shape ', X.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X,\n",
    "                                                                                     y,\n",
    "                                                                                     indices,\n",
    "                                                        random_state=104, \n",
    "                                                        stratify=y,\n",
    "                                                        test_size=0.20, \n",
    "                                                        shuffle=True)\n",
    "\n",
    "    print('Xtrain: ', len(X_train))\n",
    "    print('Xtrain shape: ', X_train.shape)\n",
    "    print('Xtest: ', len(X_test))\n",
    "    print('Ytrain: ', len(y_train))\n",
    "    print('Ytest: ', len(y_test))\n",
    "\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(random_state=0)\n",
    "    elif model_type == 'random':\n",
    "        print('Running Random Forest')\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                   random_state=42\n",
    "                                  )\n",
    "    elif model_type == 'ada':\n",
    "        model = AdaBoostClassifier(n_estimators=100,\n",
    "                                 algorithm=\"SAMME\", random_state=0)\n",
    "    elif model_type == 'tree':\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    elif model_type == 'naive':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "            \n",
    "            # pickle.dump(model, open(model_filename, 'wb'))\n",
    "    \n",
    "    print(model.score(X_train, y_train))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    result = classification_report(y_test, y_pred, \n",
    "                                   labels=[0,1])\n",
    "    prf_1 = precision_recall_fscore_support(y_test, \n",
    "                                y_pred,\n",
    "                                average='binary',\n",
    "                                pos_label=1\n",
    "                               )    \n",
    "    print(result)\n",
    "    prf_0 = precision_recall_fscore_support(y_test, \n",
    "                                y_pred,\n",
    "                                average='binary',\n",
    "                                pos_label=0\n",
    "                               )    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    #Cross validation\n",
    "    scoring = {'precision', \n",
    "               'recall',\n",
    "               'f1',\n",
    "               'roc_auc'\n",
    "              }\n",
    "\n",
    "    scores = cross_validate(model, X, y, scoring=scoring, cv=10)\n",
    "    mean_score_f1 = round(scores['test_f1'].mean(), 2)\n",
    "    std_score_f1 = round(scores['test_f1'].std(), 2)\n",
    "    \n",
    "    mean_score_precision = round(scores['test_precision'].mean(), 2)\n",
    "    std_score_precision = round(scores['test_precision'].std(), 2)\n",
    "    \n",
    "    mean_score_recall = round(scores['test_recall'].mean(), 2)\n",
    "    std_score_recall = round(scores['test_recall'].std(), 2)\n",
    "    \n",
    "     \n",
    "    mean_score_auc = round(scores['test_roc_auc'].mean(), 2)\n",
    "    std_score_auc = round(scores['test_roc_auc'].std(), 2)\n",
    "    \n",
    "    print(f'Cross validation: mean {mean_score_f1} f1 with a standard deviation of {std_score_f1}')\n",
    "    \n",
    "    print(f'Cross validation: mean {mean_score_precision} precision with a standard deviation of {std_score_precision}')\n",
    "    \n",
    "    print(f'Cross validation: mean {mean_score_recall} recall with a standard deviation of {std_score_recall}')\n",
    "    \n",
    "        \n",
    "    print(f'Cross validation: mean {mean_score_auc} auc with standard deviation of {std_score_auc}')\n",
    "    \n",
    "    final_score = {\n",
    "            'mean_f1': mean_score_f1,\n",
    "            'mean_precision': mean_score_precision,\n",
    "            'mean_recall': mean_score_recall,\n",
    "            'mean_auc': mean_score_auc\n",
    "    }\n",
    "        \n",
    "    #ROC curve\n",
    "    lr_probs = model.predict_proba(X_test)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, lr_probs[:, 1])\n",
    "    \n",
    "    # Compute the AUC score\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    if filename != None:\n",
    "        fig.savefig(f'{filename}')\n",
    "    \n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    # y_true and y_scores are the true labels and predicted scores, respectively\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test,\n",
    "                                                        lr_probs[:, 1])\n",
    "    df_pred = df.loc[indices_test]\n",
    "    df_pred['pred'] = y_pred\n",
    "    \n",
    "    return model, df_pred, roc_auc, prf_1, prf_0, mean_score_f1, std_score_f1, final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35db96ff-5e91-40c1-8819-50fa71dbce5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0acbfbde-2acf-4de8-9f24-8fd48a968d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **** logistic ****\n",
      "[1 0]\n",
      "Xtrain:  6252\n",
      "Xtrain shape:  (6252, 99)\n",
      "Xtest:  1564\n",
      "Ytrain:  6252\n",
      "Ytest:  1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404030710172744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       790\n",
      "           1       0.73      0.72      0.73       774\n",
      "\n",
      "    accuracy                           0.73      1564\n",
      "   macro avg       0.73      0.73      0.73      1564\n",
      "weighted avg       0.73      0.73      0.73      1564\n",
      "\n",
      "[[585 205]\n",
      " [213 561]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation: mean 0.72 f1 with a standard deviation of 0.04\n",
      "Cross validation: mean 0.73 precision with a standard deviation of 0.06\n",
      "Cross validation: mean 0.71 recall with a standard deviation of 0.06\n",
      "Cross validation: mean 0.79 auc with standard deviation of 0.06\n",
      "\n",
      " **** ada ****\n",
      "[1 0]\n",
      "Xtrain:  6252\n",
      "Xtrain shape:  (6252, 99)\n",
      "Xtest:  1564\n",
      "Ytrain:  6252\n",
      "Ytest:  1564\n",
      "0.7496801023672425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       790\n",
      "           1       0.72      0.73      0.72       774\n",
      "\n",
      "    accuracy                           0.72      1564\n",
      "   macro avg       0.72      0.72      0.72      1564\n",
      "weighted avg       0.72      0.72      0.72      1564\n",
      "\n",
      "[[564 226]\n",
      " [206 568]]\n",
      "Cross validation: mean 0.71 f1 with a standard deviation of 0.06\n",
      "Cross validation: mean 0.71 precision with a standard deviation of 0.06\n",
      "Cross validation: mean 0.71 recall with a standard deviation of 0.09\n",
      "Cross validation: mean 0.8 auc with standard deviation of 0.06\n",
      "\n",
      " **** random ****\n",
      "[1 0]\n",
      "Xtrain:  6252\n",
      "Xtrain shape:  (6252, 99)\n",
      "Xtest:  1564\n",
      "Ytrain:  6252\n",
      "Ytest:  1564\n",
      "Running Random Forest\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       790\n",
      "           1       0.81      0.81      0.81       774\n",
      "\n",
      "    accuracy                           0.81      1564\n",
      "   macro avg       0.81      0.81      0.81      1564\n",
      "weighted avg       0.81      0.81      0.81      1564\n",
      "\n",
      "[[643 147]\n",
      " [145 629]]\n",
      "Cross validation: mean 0.76 f1 with a standard deviation of 0.05\n",
      "Cross validation: mean 0.76 precision with a standard deviation of 0.06\n",
      "Cross validation: mean 0.76 recall with a standard deviation of 0.06\n",
      "Cross validation: mean 0.84 auc with standard deviation of 0.06\n",
      "\n",
      " **** tree ****\n",
      "[1 0]\n",
      "Xtrain:  6252\n",
      "Xtrain shape:  (6252, 99)\n",
      "Xtest:  1564\n",
      "Ytrain:  6252\n",
      "Ytest:  1564\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       790\n",
      "           1       0.70      0.70      0.70       774\n",
      "\n",
      "    accuracy                           0.70      1564\n",
      "   macro avg       0.70      0.70      0.70      1564\n",
      "weighted avg       0.70      0.70      0.70      1564\n",
      "\n",
      "[[554 236]\n",
      " [235 539]]\n",
      "Cross validation: mean 0.66 f1 with a standard deviation of 0.04\n",
      "Cross validation: mean 0.66 precision with a standard deviation of 0.04\n",
      "Cross validation: mean 0.65 recall with a standard deviation of 0.05\n",
      "Cross validation: mean 0.66 auc with standard deviation of 0.03\n",
      "\n",
      " **** naive ****\n",
      "[1 0]\n",
      "Xtrain:  6252\n",
      "Xtrain shape:  (6252, 99)\n",
      "Xtest:  1564\n",
      "Ytrain:  6252\n",
      "Ytest:  1564\n",
      "0.5652591170825336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.93      0.69       790\n",
      "           1       0.75      0.22      0.34       774\n",
      "\n",
      "    accuracy                           0.58      1564\n",
      "   macro avg       0.65      0.57      0.52      1564\n",
      "weighted avg       0.65      0.58      0.52      1564\n",
      "\n",
      "[[731  59]\n",
      " [601 173]]\n",
      "Cross validation: mean 0.31 f1 with a standard deviation of 0.09\n",
      "Cross validation: mean 0.71 precision with a standard deviation of 0.1\n",
      "Cross validation: mean 0.2 recall with a standard deviation of 0.08\n",
      "Cross validation: mean 0.68 auc with standard deviation of 0.05\n"
     ]
    }
   ],
   "source": [
    "algorithms = ['logistic', 'ada', 'random', 'tree', 'naive']\n",
    "all_results = []\n",
    "for algo in algorithms:\n",
    "\n",
    "    model, df_return, roc, prf_1, prf_0, mean_score_f1, std_score_f1, final_score = run_model(df_all_stat,\n",
    "                                  columns_not_include=[],\n",
    "                                  model_type=algo, \n",
    "                                  pca=False,\n",
    "                                  y_column = 'tweet_label',\n",
    "                                  filename=None,\n",
    "                                 just_f1=False,\n",
    "                                 find_threshold=False)\n",
    "    \n",
    "    all_results.append([algo, final_score['mean_f1'],\n",
    "                        final_score['mean_precision'],\n",
    "                        final_score['mean_recall'],\n",
    "                        final_score['mean_auc']\n",
    "                       ]\n",
    "                      )\n",
    "    \n",
    "(pd.DataFrame(data=all_results,\n",
    "              columns=['algorithm', 'mean_f1',\n",
    "                       'mean_precision', 'mean_recall',\n",
    "                       'mean_auc'\n",
    "                      ]\n",
    "             )\n",
    ").to_pickle('./data/tweet_classifier_different_algorithm.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff25b101-d715-4835-88e4-9f009ad3c1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm  mean_precision  mean_recall  mean_f1  mean_auc\n",
       "2    random            0.76         0.76     0.76      0.84\n",
       "1       ada            0.71         0.71     0.71      0.80\n",
       "0  logistic            0.73         0.71     0.72      0.79\n",
       "4     naive            0.71         0.20     0.31      0.68\n",
       "3      tree            0.66         0.65     0.66      0.66"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.read_pickle(\n",
    "    './data/tweet_classifier_different_algorithm.pkl.gz'\n",
    ")\n",
    "\n",
    "df_result[[\n",
    "    'algorithm', \n",
    "    'mean_precision', \n",
    "    'mean_recall',\n",
    "    'mean_f1', \n",
    "    'mean_auc'\n",
    "]].sort_values(by='mean_auc',\n",
    "               ascending=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b8357-a799-44fa-9037-33bc106796d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
