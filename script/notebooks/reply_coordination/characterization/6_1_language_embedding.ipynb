{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e0ce47-e33a-4fb2-ab3b-f781db9fcef1",
   "metadata": {},
   "source": [
    "#### **This notebook manually test the language translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805f9c0e-15aa-47be-bde4-358960034de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "\n",
    "import config.config as config_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb775f4d-1960-4514-9c4e-78f3c34dc669",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275fdafe-2a05-4ba2-8d66-6c6737370d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1831668/2584407693.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_pos.append(df_neg)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "balanced = config['BALANCED']\n",
    "\n",
    "positive_conv = balanced['balanced_pos_conversation']\n",
    "df_pos = pd.read_pickle(positive_conv)\n",
    "\n",
    "negative_conv = balanced['balanced_neg_conversation']\n",
    "df_neg = pd.read_pickle(negative_conv)\n",
    "\n",
    "df = df_pos.append(df_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53009737-ecda-407a-b5f4-c9e6094fb203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Remove non language tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d391c2a-391c-4ce3-bc67-a5e39f7e797e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2673091 entries, 0 to 2673090\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   tweet_text       object \n",
      " 1   conversation_id  object \n",
      " 2   replier_tweetid  object \n",
      " 3   replier_userid   object \n",
      " 4   poster_userid    object \n",
      " 5   poster_tweetid   object \n",
      " 6   tweet_time       object \n",
      " 7   tweet_language   object \n",
      " 8   replier_label    int64  \n",
      " 9   year             object \n",
      " 10  campaign         object \n",
      " 11  tweet_label      int64  \n",
      " 12  tweet_time_year  object \n",
      " 13  common           float64\n",
      " 14  id               object \n",
      " 15  username         object \n",
      "dtypes: float64(1), int64(2), object(13)\n",
      "memory usage: 346.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "756c4044-c92d-4bbe-8e14-638ca3ab5b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(twitter_hp)\n",
    "\n",
    "df_rem = twitter_hp.remove_non_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6065114-9bed-4227-8285-2e3a9f6f7056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tr\n",
       "1    tr\n",
       "2    tr\n",
       "3    tr\n",
       "5    tr\n",
       "Name: tweet_language, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rem['tweet_language'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd3fb366-f11e-420d-92d6-e3b26575aa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data :  2673091\n",
      "Total remaining : 2425668\n",
      "Total english replies : 85560\n",
      "Total other languages : 2340108\n"
     ]
    }
   ],
   "source": [
    "total_data = len(df)\n",
    "total_remaining = len(df_rem)\n",
    "df_eng = df_rem.loc[df_rem['tweet_language'] == 'en']\n",
    "eng_replies = len(df_eng)\n",
    "\n",
    "print('Total data : ', total_data)\n",
    "print('Total remaining :', total_remaining)\n",
    "print('Total english replies :', eng_replies)\n",
    "print('Total other languages :', total_remaining - eng_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3f8e92a-c749-4af5-aced-c4ef2faa8c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_not_eng = df_rem.loc[~(df_rem['tweet_language'] == 'en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f8b536d-ba94-459e-919f-7842e7043189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_eng['tweet_language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af2b8b5-2ecc-4ad2-be8b-1276fdf729e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tr', 'ar', 'es', 'it', 'in', 'sl', 'sr', 'tl', 'pl', 'lv', 'pt',\n",
       "       'sv', 'is', 'ru', 'et', 'cs', 'hu', 'bg', 'ht', 'lt', 'eu', 'nl',\n",
       "       'hi', 'uk', 'no', 'fi', 'da', 'zh', 'fr', 'ca', 'fa', 'ur', 'ro',\n",
       "       'de', 'cy', 'ja', 'th', 'vi', 'bn', 'ko', 'el', 'ne', 'ta', 'ml',\n",
       "       'ckb', 'hr', 0, 'ps', 'bs', 'iw', 'sd', 'sk', 'art', 'am'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_eng['tweet_language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f12be4b-337e-4b5b-9250-4e45132c188c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3819607/1054441733.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1227488    @BorkoStef @moon13elup laze se naveloiko,samo ...\n",
       "2633183    @SamsungRu –ö–æ–Ω–∫—É—Ä—Å—ã - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ! –î–∞–≤–Ω–æ –ø–æ—Ä–∞ —Ç...\n",
       "2633184    @SamsungRu –Ø –¥–µ–≤–æ—á–∫–∞! –Ø –Ω–µ —Ö–æ—á—É –Ω–∏—á–µ–≥–æ —Ä–µ—à–∞—Ç—å!...\n",
       "2633185    @SamsungRu –ü–æ–∂–∞–ª–µ–π—Ç–µ –±–µ–¥–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞! –ü–æ–¥–∞—Ä–∏—Ç...\n",
       "2633186       @SamsungRu –∞ —á—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ç–æ? #—Å–º–∞—Ä—Ç—Ñ–æ–Ω4D\n",
       "2633187    @SamsungRu –ö–æ–Ω–∫—É—Ä—Å—ã - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ! –î–∞–≤–Ω–æ –ø–æ—Ä–∞ —Ç...\n",
       "2633188    @SamsungRu 8 –º–∞—Ä—Ç–∞ –≤–µ–¥—å –Ω–µ–¥–∞–≤–Ω–æ –±—ã–ª–æ, –Ω—É–∂–Ω–æ –¥–µ...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "df_not_eng.loc[df_not_eng['tweet_language'] == 0]['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9d352-8b06-4e15-b4ee-6af74d7360e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Google Cloud Translation API:**\n",
    "$20 per 1 million characters for translation, spaces are included, empty query charged for one character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392b060-ecb5-4a08-a2bd-160dc566c0bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Microsoft Translator Text API:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3560851-2dc6-440a-82cb-8da46e0b0dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **MBart and MBart50**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa7995-803b-4ffc-ad64-cc9e7bd8c6f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Language covered**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98411e7-7188-4578-8167-7725ce52f728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mbart = {\n",
    "'Arabic' : 'ar_AR', \n",
    "'Czech' : 'cs_CZ', \n",
    "'German' : 'de_DE',\n",
    "'English': 'en_XX', \n",
    "'Spanish' : 'es_XX', \n",
    "'Estonian' : 'et_EE', \n",
    "'Finnish' : 'fi_FI', \n",
    "'French' : 'fr_XX', \n",
    "'Gujarati' : 'gu_IN', \n",
    "'Hindi': 'hi_IN', \n",
    "'Italian': 'it_IT', \n",
    "'Japanese' : 'ja_XX', \n",
    "'Kazakh' : 'kk_KZ', \n",
    "'Korean' : 'ko_KR', \n",
    "'Lithuanian' : 'lt_LT', \n",
    "'Latvian' : 'lv_LV', \n",
    "'Burmese': 'my_MM', \n",
    "'Nepali' : 'ne_NP', \n",
    "'Dutch' : 'nl_XX', \n",
    "'Romanian': 'ro_RO', \n",
    "'Russian' : 'ru_RU', \n",
    "'Sinhala' : 'si_LK', \n",
    "'Turkish' : 'tr_TR', \n",
    "'Vietnamese' : 'vi_VN', \n",
    "'Chinese': 'zh_CN', \n",
    "'Afrikaans' : 'af_ZA', \n",
    "'Azerbaijani' : 'az_AZ',\n",
    "'Bengali' : 'bn_IN', \n",
    "'Persian' : 'fa_IR', \n",
    "'Hebrew' : 'he_IL', \n",
    "'Croatian' : 'hr_HR', \n",
    "'Indonesian' : 'id_ID', \n",
    "'Georgian': 'ka_GE', \n",
    "'Khmer' : 'km_KH',\n",
    "'Macedonian' : 'mk_MK', \n",
    "'Malayalam' : 'ml_IN', \n",
    "'Mongolian' : 'mn_MN', \n",
    "'Marathi' : 'mr_IN', \n",
    "'Polish' : 'pl_PL', \n",
    "'Pashto' : 'ps_AF',\n",
    "'Portuguese' : 'pt_XX', \n",
    "'Swedish': 'sv_SE', \n",
    "'Swahili' : 'sw_KE', \n",
    "'Tamil' : 'ta_IN', \n",
    "'Telugu' : 'te_IN',\n",
    "'Thai' : 'th_TH', \n",
    "'Tagalog' : 'tl_XX', \n",
    "'Ukrainian' : 'uk_UA', \n",
    "'Urdu' : 'ur_PK', \n",
    "'Xhosa' : 'xh_ZA',\n",
    "'Galician' :'gl_ES', \n",
    "'Slovene' : 'sl_SI'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83758bda-c61c-4c80-8f28-f881eeba2d52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Twitter language code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f73fbd6-9e98-4663-8a43-d6587266403f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "got_codes = ['tr', 'ar', 'es', 'it', 'in', 'sl', 'sr', 'tl', 'pl', 'lv', 'pt',\n",
    "           'sv', 'is', 'ru', 'et', 'cs', 'hu', 'bg', 'ht', 'lt', 'eu', 'nl',\n",
    "           'hi', 'uk', 'no', 'fi', 'da', 'zh', 'fr', 'ca', 'fa', 'ur', 'ro',\n",
    "           'de', 'cy', 'ja', 'th', 'vi', 'bn', 'ko', 'el', 'ne', 'ta', 'ml',\n",
    "           'ckb', 'hr', 0, 'ps', 'bs', 'iw', 'sd', 'sk', 'art', 'am', 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b6b7d9c-8e55-439d-8457-e480d36ecb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#34 languages\n",
    "\n",
    "twitter_codes_available ={\n",
    "'English': 'en',\n",
    "'Arabic':'ar',\n",
    "'Bengali':'bn',\n",
    "'Czech':'cs',\n",
    "'Danish':'da',\n",
    "'German':'de',\n",
    "'Greek':'el',\n",
    "'Spanish':'es',\n",
    "'Persian':'fa',\n",
    "'Finnish':'fi',\n",
    "'Tagalog':'fil',\n",
    "'French':'fr',\n",
    "'Hebrew':'he',\n",
    "'Hindi':'hi',\n",
    "'Hungarian':'hu',\n",
    "'Indonesian':'id',\n",
    "'Italian':'it',\n",
    "'Japanese':'ja',\n",
    "'Korean':'ko',\n",
    "'Malay':'sa',\n",
    "'Dutch':'nl',\n",
    "'Norwegian':'no',\n",
    "'Polish':'pl',\n",
    "'Portuguese':'pt',\n",
    "'Romanian':'ro',\n",
    "'Russian':'ru',\n",
    "'Swedish':'sv',\n",
    "'Thai':'th',\n",
    "'Turkish':'tr',\n",
    "'Ukrainian':'uk',\n",
    "'Urdu':'ur',\n",
    "'Vietnamese':'vi',\n",
    "'Chinese (Simplified)':'zh-cn',\n",
    "'Chinese (Traditional)': 'zh-tw',\n",
    "'Chinese': 'zh', \n",
    "    \n",
    "##### got from ChatGPT\n",
    "'Slovak': 'sk',\n",
    "'Tamil': 'ta',\n",
    "'Slovenian': 'sl',\n",
    "'Latvian': 'lv',\n",
    "'Estonian': 'et',\n",
    "'Icelandic': 'is',\n",
    "'Hebrew': 'iw',\n",
    "'Welsh': 'cy',\n",
    "'Croatian': 'hr',\n",
    "'Pashto': 'ps',\n",
    "'Kurdish': 'ckb',\n",
    "'Haitian Creole': 'ht',\n",
    "'Basque': 'eu',\n",
    "'Bulgarian': 'bg',\n",
    "'Catalan': 'ca',\n",
    "'Bosnian': 'bs',\n",
    "'Tagalog': 'tl',\n",
    "'Amharic': 'am',\n",
    "'Sindhi': 'sd',\n",
    "'Nepali': 'ne',\n",
    "'Malayalam': 'ml',\n",
    "'Serbian': 'sr',\n",
    "'Lithuanian': 'lt',\n",
    "'Indonesian': 'in',\n",
    "'Artificial (used for artificially generated text)': 'art',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6827d6-c7af-421a-9677-f040665c9c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not available :  {0}\n",
      "Country not available : {'Catalan', 'Serbian', 'Norwegian', 'Bulgarian', 'Hungarian', 'Welsh', 'Kurdish', 'Haitian Creole', 'Bosnian', 'Greek', 'Slovak', 'Malay', 'Basque', 'Artificial (used for artificially generated text)', 'Sindhi', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Icelandic', 'Amharic', 'Danish', 'Slovenian'}\n",
      "Total not available : 21\n"
     ]
    }
   ],
   "source": [
    "values = set(got_codes) - set(twitter_codes_available.values())\n",
    "print('Not available : ', values)\n",
    "\n",
    "not_available_country = set(twitter_codes_available.keys()) - set(mbart.keys())\n",
    "\n",
    "print('Country not available :', not_available_country)\n",
    "print('Total not available :', len(not_available_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52cc7e6-bbec-4aa6-814f-c3dd5390e0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>replier_tweetid</th>\n",
       "      <th>replier_userid</th>\n",
       "      <th>poster_userid</th>\n",
       "      <th>poster_tweetid</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>tweet_language</th>\n",
       "      <th>replier_label</th>\n",
       "      <th>year</th>\n",
       "      <th>campaign</th>\n",
       "      <th>tweet_label</th>\n",
       "      <th>tweet_time_year</th>\n",
       "      <th>common</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1312085</th>\n",
       "      <td>@AnwarGargash ÿØ ÿπÿ±ÿ®Ÿä ÿßŸÖÿßÿ±ÿßÿ™Ÿà ÿØ ÿ®Ÿáÿ±ŸÜ€åŸà ⁄Üÿßÿ±Ÿà Ÿàÿ≤Ÿä...</td>\n",
       "      <td>1109043885567807488</td>\n",
       "      <td>1109358953694224384</td>\n",
       "      <td>1107345973070753792</td>\n",
       "      <td>348378205</td>\n",
       "      <td>1109043885567807488</td>\n",
       "      <td>2019-03-23 07:39:20+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348378205</td>\n",
       "      <td>AnwarGargash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312092</th>\n",
       "      <td>@AnwarGargash ŸáŸà ÿ™ÿßÿ≥Ÿà ÿ™Ÿá ŸÜŸá ⁄öÿßŸäŸä ⁄Ü€ê ÿØ ŸÖÿ≠ÿßÿ±ÿ®Ÿà ⁄©...</td>\n",
       "      <td>1109043885567807488</td>\n",
       "      <td>1109317763519045634</td>\n",
       "      <td>918326626299113472</td>\n",
       "      <td>348378205</td>\n",
       "      <td>1109043885567807488</td>\n",
       "      <td>2019-03-23 04:55:39+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348378205</td>\n",
       "      <td>AnwarGargash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748073</th>\n",
       "      <td>@javerias Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ÿ¢ÿ≥€åÿß ⁄©€ê €åŸà ŸÖŸáŸÖ Ÿá€êŸàÿßÿØ ÿØ€å ÿßŸà ÿØ...</td>\n",
       "      <td>1097121736557060096</td>\n",
       "      <td>1097229325198413824</td>\n",
       "      <td>406852778</td>\n",
       "      <td>69807765</td>\n",
       "      <td>1097121736557060096</td>\n",
       "      <td>2019-02-17 20:20:31+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69807765</td>\n",
       "      <td>javerias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766105</th>\n",
       "      <td>@Rawaak ÿß€åÿß ŸæŸàŸá€êÿØÿ¶ ⁄Ü€ê ŸÑŸàŸÖ⁄ìŸÜ€å ŸæŸàŸáŸÜÿ™ŸàŸÜ €åŸà€ê ŸÖÿ≥ŸÑŸÖÿß...</td>\n",
       "      <td>1450198393129668616</td>\n",
       "      <td>1450407708235124742</td>\n",
       "      <td>419385731</td>\n",
       "      <td>43307251</td>\n",
       "      <td>1450198393129668616</td>\n",
       "      <td>2021-10-19 10:25:19+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43307251</td>\n",
       "      <td>Rawaak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095192</th>\n",
       "      <td>@abqatar ÿßŸÑŸÑŸá ÿ¨  ÿØ ÿ¨ŸÜÿ™ ÿßŸÑŸÅÿ±ŸàÿØÿ≥ ⁄©⁄ö€ê ⁄ÅÿßŸä Ÿàÿ±⁄©⁄ìŸä</td>\n",
       "      <td>1510288739171553288</td>\n",
       "      <td>1510575682430115846</td>\n",
       "      <td>1486124290391093249</td>\n",
       "      <td>417870919</td>\n",
       "      <td>1510288739171553288</td>\n",
       "      <td>2022-04-03 11:11:22+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>32.0</td>\n",
       "      <td>417870919</td>\n",
       "      <td>abqatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441170</th>\n",
       "      <td>@Bnt_mohammed77 ‚öòŸÄ‚ùÉŸÄ‚ùÉŸè‚öò‚ô°‚ô°‚úî üåπüåπ\\nÿßŸÑŸÑŸÄ ŸÄ ŸÄ ŸÄŸÄÔÆ™ Ÿäÿ≥...</td>\n",
       "      <td>1002779044092497921</td>\n",
       "      <td>1004157064061571072</td>\n",
       "      <td>979971489016446977</td>\n",
       "      <td>1947507715</td>\n",
       "      <td>1002779044092497921</td>\n",
       "      <td>2018-06-06 00:24:35+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1947507715</td>\n",
       "      <td>Bnt_mohammed77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484281</th>\n",
       "      <td>@TurkiShalhoub ÿßŸÜÿ¥ÿßÿ° ÿßŸÑŸÑŸá ⁄ÜŸä ŸÜŸàÿ± ÿ∑ŸàŸÅÿßŸÜŸàŸÜŸà ÿ®Ÿá ÿ±...</td>\n",
       "      <td>1581734724799586304</td>\n",
       "      <td>1581738912892223489</td>\n",
       "      <td>1570557853319954434</td>\n",
       "      <td>3385869567</td>\n",
       "      <td>1581734724799586304</td>\n",
       "      <td>2022-10-16 20:08:38+00:00</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3385869567</td>\n",
       "      <td>TurkiShalhoub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet_text  \\\n",
       "1312085  @AnwarGargash ÿØ ÿπÿ±ÿ®Ÿä ÿßŸÖÿßÿ±ÿßÿ™Ÿà ÿØ ÿ®Ÿáÿ±ŸÜ€åŸà ⁄Üÿßÿ±Ÿà Ÿàÿ≤Ÿä...   \n",
       "1312092  @AnwarGargash ŸáŸà ÿ™ÿßÿ≥Ÿà ÿ™Ÿá ŸÜŸá ⁄öÿßŸäŸä ⁄Ü€ê ÿØ ŸÖÿ≠ÿßÿ±ÿ®Ÿà ⁄©...   \n",
       "1748073  @javerias Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ ÿ¢ÿ≥€åÿß ⁄©€ê €åŸà ŸÖŸáŸÖ Ÿá€êŸàÿßÿØ ÿØ€å ÿßŸà ÿØ...   \n",
       "766105   @Rawaak ÿß€åÿß ŸæŸàŸá€êÿØÿ¶ ⁄Ü€ê ŸÑŸàŸÖ⁄ìŸÜ€å ŸæŸàŸáŸÜÿ™ŸàŸÜ €åŸà€ê ŸÖÿ≥ŸÑŸÖÿß...   \n",
       "1095192       @abqatar ÿßŸÑŸÑŸá ÿ¨  ÿØ ÿ¨ŸÜÿ™ ÿßŸÑŸÅÿ±ŸàÿØÿ≥ ⁄©⁄ö€ê ⁄ÅÿßŸä Ÿàÿ±⁄©⁄ìŸä   \n",
       "1441170  @Bnt_mohammed77 ‚öòŸÄ‚ùÉŸÄ‚ùÉŸè‚öò‚ô°‚ô°‚úî üåπüåπ\\nÿßŸÑŸÑŸÄ ŸÄ ŸÄ ŸÄŸÄÔÆ™ Ÿäÿ≥...   \n",
       "2484281  @TurkiShalhoub ÿßŸÜÿ¥ÿßÿ° ÿßŸÑŸÑŸá ⁄ÜŸä ŸÜŸàÿ± ÿ∑ŸàŸÅÿßŸÜŸàŸÜŸà ÿ®Ÿá ÿ±...   \n",
       "\n",
       "             conversation_id      replier_tweetid       replier_userid  \\\n",
       "1312085  1109043885567807488  1109358953694224384  1107345973070753792   \n",
       "1312092  1109043885567807488  1109317763519045634   918326626299113472   \n",
       "1748073  1097121736557060096  1097229325198413824            406852778   \n",
       "766105   1450198393129668616  1450407708235124742            419385731   \n",
       "1095192  1510288739171553288  1510575682430115846  1486124290391093249   \n",
       "1441170  1002779044092497921  1004157064061571072   979971489016446977   \n",
       "2484281  1581734724799586304  1581738912892223489  1570557853319954434   \n",
       "\n",
       "        poster_userid       poster_tweetid                 tweet_time  \\\n",
       "1312085     348378205  1109043885567807488  2019-03-23 07:39:20+00:00   \n",
       "1312092     348378205  1109043885567807488  2019-03-23 04:55:39+00:00   \n",
       "1748073      69807765  1097121736557060096  2019-02-17 20:20:31+00:00   \n",
       "766105       43307251  1450198393129668616  2021-10-19 10:25:19+00:00   \n",
       "1095192     417870919  1510288739171553288  2022-04-03 11:11:22+00:00   \n",
       "1441170    1947507715  1002779044092497921  2018-06-06 00:24:35+00:00   \n",
       "2484281    3385869567  1581734724799586304  2022-10-16 20:08:38+00:00   \n",
       "\n",
       "        tweet_language  replier_label year campaign  tweet_label  \\\n",
       "1312085             ps              0  NaN      NaN            1   \n",
       "1312092             ps              0  NaN      NaN            1   \n",
       "1748073             ps              0  NaN      NaN            1   \n",
       "766105              ps              0  NaN      NaN            0   \n",
       "1095192             ps              0  NaN      NaN            0   \n",
       "1441170             ps              0  NaN      NaN            0   \n",
       "2484281             ps              0  NaN      NaN            0   \n",
       "\n",
       "        tweet_time_year  common          id        username  \n",
       "1312085      2019-03-23     NaN   348378205    AnwarGargash  \n",
       "1312092      2019-03-23     NaN   348378205    AnwarGargash  \n",
       "1748073      2019-02-17     NaN    69807765        javerias  \n",
       "766105       2021-10-19     1.0    43307251          Rawaak  \n",
       "1095192      2022-04-03    32.0   417870919         abqatar  \n",
       "1441170      2018-06-06     2.0  1947507715  Bnt_mohammed77  \n",
       "2484281      2022-10-16    74.0  3385869567   TurkiShalhoub  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rem.loc[df_rem['tweet_language'] == 'sd']\n",
    "df_rem.loc[df_rem['tweet_language'] == 'ps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8faa4-bca6-4333-9edf-c6dbe1e04007",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **MBart-50 for 50 languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac9f47b8-eddd-4ba5-8528-75473dd8963f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-01 16:19:14.316657: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/N/slate/potem/miniconda3/lib/python3.10/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Secretary-General of the United Nations says there is no military solution in Syria.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_hi = \"‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞ ‡§ï‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ ‡§ï‡§π‡§®‡§æ ‡§π‡•à ‡§ï‡§ø ‡§∏‡•Ä‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§∏‡•à‡§®‡•ç‡§Ø ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à\"\n",
    "article_ar = \"ÿßŸÑÿ£ŸÖŸäŸÜ ÿßŸÑÿπÿßŸÖ ŸÑŸÑÿ£ŸÖŸÖ ÿßŸÑŸÖÿ™ÿ≠ÿØÿ© ŸäŸÇŸàŸÑ ÿ•ŸÜŸá ŸÑÿß ŸäŸàÿ¨ÿØ ÿ≠ŸÑ ÿπÿ≥ŸÉÿ±Ÿä ŸÅŸä ÿ≥Ÿàÿ±Ÿäÿß.\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate Hindi to French\n",
    "tokenizer.src_lang = \"hi_IN\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"])\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "# => \"Le chef de l 'ONU affirme qu 'il n 'y a pas de solution militaire en Syria.\"\n",
    "\n",
    "# translate Arabic to English\n",
    "tokenizer.src_lang = \"ar_AR\"\n",
    "encoded_ar = tokenizer(article_ar, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_ar, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "# => \"The Secretary-General of the United Nations says there is no military solution in Syria.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033f97f7-47d2-477d-8b4e-4df59e68debd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_ar.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7a676-5787-4048-abbb-d2cd75492af0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **LaBSE- Language-agnostic BERT sentence embedding model supporting 109 languages.**\n",
    "\n",
    "From Google <br />\n",
    "\n",
    "@misc{feng2020languageagnostic, <br />\n",
    "      title={Language-agnostic BERT Sentence Embedding}, <br />\n",
    "      author={Fangxiaoyu Feng and Yinfei Yang and Daniel Cer and Naveen Arivazhagan and Wei Wang}, <br />\n",
    "      year={2020}, <br />\n",
    "      eprint={2007.01852},<br />\n",
    "      archivePrefix={arXiv},<br />\n",
    "      primaryClass={cs.CL}<br />\n",
    "}<br />\n",
    "@misc{feng2020languageagnostic, <br />\n",
    "      title={Language-agnostic BERT Sentence Embedding},<br />\n",
    "      author={Fangxiaoyu Feng and Yinfei Yang and Daniel Cer and Naveen Arivazhagan and Wei Wang},<br />\n",
    "      year={2020},<br />\n",
    "      eprint={2007.01852},<br />\n",
    "      archivePrefix={arXiv},<br />\n",
    "      primaryClass={cs.CL}<br />\n",
    "}<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31583b1c-f76b-4545-b7d4-43bd08d502e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Languages supported in LaBSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d8893b7-fbce-4349-8490-ac52b32bc8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labse = {\n",
    "    'af': 'AFRIKAANS',\n",
    "    'ht': 'HAITIAN CREOLE',\n",
    "    'pt': 'PORTUGUESE',\n",
    "    'am': 'AMHARIC',\n",
    "    'hu': 'HUNGARIAN',\n",
    "    'ro': 'ROMANIAN',\n",
    "    'ar': 'ARABIC',\n",
    "    'hy': 'ARMENIAN',\n",
    "    'ru': 'RUSSIAN',\n",
    "    'as': 'ASSAMESE',\n",
    "    'id': 'INDONESIAN',\n",
    "    'rw': 'KINYARWANDA',\n",
    "    'az': 'AZERBAIJANI',\n",
    "    'ig': 'IGBO',\n",
    "    'si': 'SINHALESE',\n",
    "    'be': 'BELARUSIAN',\n",
    "    'is': 'ICELANDIC',\n",
    "    'sk': 'SLOVAK',\n",
    "    'bg': 'BULGARIAN',\n",
    "    'it': 'ITALIAN',\n",
    "    'sl': 'SLOVENIAN',\n",
    "    'bn': 'BENGALI',\n",
    "    'ja': 'JAPANESE',\n",
    "    'sm': 'SAMOAN',\n",
    "    'bo': 'TIBETAN',\n",
    "    'jv': 'JAVANESE',\n",
    "    'sn': 'SHONA',\n",
    "    'bs': 'BOSNIAN',\n",
    "    'ka': 'GEORGIAN',\n",
    "    'so': 'SOMALI',\n",
    "    'ca': 'CATALAN',\n",
    "    'kk': 'KAZAKH',\n",
    "    'sq': 'ALBANIAN',\n",
    "    'ceb': 'CEBUANO',\n",
    "    'km': 'KHMER',\n",
    "    'sr': 'SERBIAN',\n",
    "    'co': 'CORSICAN',\n",
    "    'kn': 'KANNADA',\n",
    "    'st': 'SESOTHO',\n",
    "    'cs': 'CZECH',\n",
    "    'ko': 'KOREAN',\n",
    "    'su': 'SUNDANESE',\n",
    "    'cy': 'WELSH',\n",
    "    'ku': 'KURDISH',\n",
    "    'sv': 'SWEDISH',\n",
    "    'da': 'DANISH',\n",
    "    'ky': 'KYRGYZ',\n",
    "    'sw': 'SWAHILI',\n",
    "    'de': 'GERMAN',\n",
    "    'la': 'LATIN',\n",
    "    'ta': 'TAMIL',\n",
    "    'el': 'GREEK',\n",
    "    'lb': 'LUXEMBOURGISH',\n",
    "    'te': 'TELUGU',\n",
    "    'en': 'ENGLISH',\n",
    "    'lo': 'LAOTHIAN',\n",
    "    'tg': 'TAJIK',\n",
    "    'eo': 'ESPERANTO',\n",
    "    'lt': 'LITHUANIAN',\n",
    "    'th': 'THAI',\n",
    "    'es': 'SPANISH',\n",
    "    'lv': 'LATVIAN',\n",
    "    'tk': 'TURKMEN',\n",
    "    'et': 'ESTONIAN',\n",
    "    'mg': 'MALAGASY',\n",
    "    'tl': 'TAGALOG',\n",
    "    'eu': 'BASQUE',\n",
    "    'mi': 'MAORI',\n",
    "    'tr': 'TURKISH',\n",
    "    'fa': 'PERSIAN',\n",
    "    'mk': 'MACEDONIAN',\n",
    "    'tt': 'TATAR',\n",
    "    'fi': 'FINNISH',\n",
    "    'ml': 'MALAYALAM',\n",
    "    'ug': 'UIGHUR',\n",
    "    'fr': 'FRENCH',\n",
    "    'mn': 'MONGOLIAN',\n",
    "    'uk': 'UKRAINIAN',\n",
    "    'fy': 'FRISIAN',\n",
    "    'mr' : 'MARATHI',\n",
    "    'ur' : 'URDU',\n",
    "    'ga' : 'IRISH',\n",
    "    'ms' : 'MALAY',\n",
    "    'uz' : 'UZBEK',\n",
    "    'gd' : 'SCOTS_GAELIC',\n",
    "    'mt' : 'MALTESE',\n",
    "    'vi' : 'VIETNAMESE',\n",
    "    'gl' : 'GALICIAN',\n",
    "    'my' : 'BURMESE',\n",
    "    'wo' : 'WOLOF',\n",
    "    'gu' : 'GUJARATI',\n",
    "    'ne' : 'NEPALI',\n",
    "    'xh' : 'XHOSA',\n",
    "    'ha' : 'HAUSA',\n",
    "    'nl' : 'DUTCH',\n",
    "    'yi' : 'YIDDISH',\n",
    "    'haw': 'HAWAIIAN',\n",
    "    'no' : 'NORWEGIAN',\n",
    "    'yo' : 'YORUBA',\n",
    "    'he' : 'HEBREW',\n",
    "    'ny' : 'NYANJA',\n",
    "    'zh' : 'CHINESE',\n",
    "    'hi' : 'HINDI',\n",
    "    'or' : 'ORIYA',\n",
    "    'zu' : 'ZULU',\n",
    "    'hmn': 'HMONG',\n",
    "    'pa' : 'PUNJABI',\n",
    "    'hr' : 'CROATIAN',\n",
    "    'pl' : 'POLISH',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85aca6bb-670b-45ff-b0d4-0eae0c4ea652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a363849-232f-4507-85fe-64947866018a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not available :  {'in', 'art', 'zh-tw', 'zh-cn', 'sa', 'ckb', 'iw', 'ps', 'sd'}\n",
      "\n",
      " Country not available : \n",
      " {'pashto', 'chinese (traditional)', 'artificial (used for artificially generated text)', 'chinese (simplified)', 'sindhi'}\n",
      "\n",
      " Total not available : 5\n"
     ]
    }
   ],
   "source": [
    "twitter_code = list(set(twitter_codes_available.values()))\n",
    "twitter_code = [x.lower() for x in twitter_code]\n",
    "labse_code = list(set(labse.keys()))\n",
    "labse_code = [x.lower() for x in labse_code]\n",
    "\n",
    "values = set(twitter_code) - set(labse_code)\n",
    "print('Not available : ', values)\n",
    "\n",
    "twitter_countries = set(twitter_codes_available.keys())\n",
    "\n",
    "twitter_countries = [x.lower() for x in twitter_countries]\n",
    "\n",
    "labse_countries = set(labse.values())\n",
    "labse_countries = [x.lower() for x in labse_countries]\n",
    "not_available_country =  set(twitter_countries) - set(labse_countries)\n",
    "\n",
    "print('\\n Country not available : \\n', not_available_country)\n",
    "print('\\n Total not available :', len(not_available_country))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d2721-9b58-4bfa-b76e-f0b6e24f42a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### **Example use of labse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "009255ce-a1a7-42db-a86c-08d66e370764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8598]])\n",
      "tensor([[0.8709]])\n",
      "tensor([[0.8003]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "model = model.eval()\n",
    "\n",
    "english_sentences = [\n",
    "    # \"puppies\",\n",
    "    \"Puppies are nice.\",\n",
    "    # \"I enjoy taking long walks along the beach with my dog.\",\n",
    "]\n",
    "english_inputs = tokenizer(english_sentences, \n",
    "                           return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    english_outputs = model(**english_inputs)\n",
    "    \n",
    "english_embeddings = english_outputs.pooler_output\n",
    "\n",
    "italian_sentences = [\n",
    "    # \"cuccioli\",\n",
    "    \"I cuccioli sono carini.\",\n",
    "    # \"Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.\",\n",
    "]\n",
    "japanese_sentences = [\n",
    "    # \"Áä¨\",\n",
    "    \"Â≠êÁä¨„ÅØ„ÅÑ„ÅÑ„Åß„Åô„ÄÇ\",\n",
    "    # \"ÁßÅ„ÅØÁä¨„Å®‰∏ÄÁ∑í„Å´„Éì„Éº„ÉÅ„ÇíÊï£Ê≠©„Åô„Çã„ÅÆ„ÅåÂ•Ω„Åç„Åß„Åô\"\n",
    "]\n",
    "italian_inputs = tokenizer(italian_sentences, return_tensors=\"pt\", padding=True)\n",
    "japanese_inputs = tokenizer(japanese_sentences, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    italian_outputs = model(**italian_inputs)\n",
    "    japanese_outputs = model(**japanese_inputs)\n",
    "\n",
    "italian_embeddings = italian_outputs.pooler_output\n",
    "japanese_embeddings = japanese_outputs.pooler_output\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def similarity(embeddings_1, embeddings_2):\n",
    "    normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "    normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "    return torch.matmul(\n",
    "        normalized_embeddings_1, normalized_embeddings_2.transpose(0, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "print(similarity(english_embeddings, italian_embeddings))\n",
    "print(similarity(english_embeddings, japanese_embeddings))\n",
    "print(similarity(italian_embeddings, japanese_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36961076-b662-4aca-92b6-20defe475206",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(english_embeddings[0]).reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6240a043-80c0-48d5-ae4c-058d35530133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6318207"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(english_embeddings,\n",
    "                italian_embeddings)[0][0]\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76777a2-7716-43af-9e19-f2c73d48916d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Testing for tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09e2c46c-1c2a-4828-84f6-5420b29db22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_each_language(df, \n",
    "                       language_column='tweet_language'\n",
    "                      ):\n",
    "    \n",
    "    import torch\n",
    "    from transformers import BertModel, BertTokenizerFast\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "    model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "    model = model.eval()\n",
    "\n",
    "    languages = df[language_column].unique()\n",
    "    for lang in languages:\n",
    "        print(lang)\n",
    "        df_lang = (df\n",
    "                   .loc[df[language_column] == lang]\n",
    "                   .groupby([language_column])\n",
    "                   .head(1)\n",
    "                  )\n",
    "        tweet = df_lang['tweet_text'].tolist()\n",
    "        tweet_clean = clean_hp.remove_mentions(tweet[0])\n",
    "        \n",
    "        inputs = tokenizer(tweet, \n",
    "                           return_tensors=\"pt\",\n",
    "                           padding=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "\n",
    "        embeddings = output.pooler_output\n",
    "        print(embeddings.shape)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d03d52fb-4391-4942-a850-54b3db69ba7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_each_language(df_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656041d-c902-4379-bbb0-a87d06587699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Get embedding and cosine of pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290984ab-3848-458b-91c9-1b51d6a88df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1819911/2584407693.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_pos.append(df_neg)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "balanced = config['BALANCED']\n",
    "\n",
    "positive_conv = balanced['balanced_pos_conversation']\n",
    "df_pos = pd.read_pickle(positive_conv)\n",
    "\n",
    "negative_conv = balanced['balanced_neg_conversation']\n",
    "df_neg = pd.read_pickle(negative_conv)\n",
    "\n",
    "df = df_pos.append(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2ce5178-c769-4bac-9beb-c267fbfe6c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding(df, filename):\n",
    "    import torch\n",
    "    from transformers import BertModel, BertTokenizerFast\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "    model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "    model = model.eval()\n",
    "\n",
    "    all_replies = []\n",
    "    total = len(df)\n",
    "    print(f'\\n *** Starting the embedding process: {total} *** \\n')\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        text = row[1]['tweet_text']\n",
    "        data = row[1]\n",
    "        \n",
    "        tweet_clean = clean_hp.remove_mentions(text)\n",
    "        tweet_clean = clean_hp.remove_hashtags(tweet_clean)\n",
    "        tweet_clean = clean_hp.remove_URL(tweet_clean)\n",
    "\n",
    "        inputs = tokenizer(tweet_clean, \n",
    "                           return_tensors=\"pt\",\n",
    "                           padding=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "\n",
    "        embeddings = output.pooler_output\n",
    "        \n",
    "        all_replies.append([data['replier_tweetid'],\n",
    "                            data['poster_userid'],\n",
    "                            data['poster_tweetid'],\n",
    "                            data['replier_userid'],\n",
    "                            embeddings\n",
    "                           ])\n",
    "        if len(all_replies) % 1000 == 0:\n",
    "            total = len(all_replies)\n",
    "            \n",
    "            print(f'{total} done!')\n",
    "            \n",
    "    (pd.DataFrame(data=all_replies,\n",
    "                 columns=['replier_tweetid',\n",
    "                          'poster_userid',\n",
    "                          'poster_tweetid',\n",
    "                          'replier_userid'\n",
    "                         ]\n",
    "                )\n",
    "    ).to_pickle(filename)\n",
    "    \n",
    "    print('\\n *** Ending the embedding process *** \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47327bd1-64b0-49bb-81ea-5bcf31dfe840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "embedding_path = config['EMBEDDINGS_PATH']\n",
    "filename = embedding_path['reply_multilanguage_embedding']\n",
    "\n",
    "\n",
    "get_embedding(df, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15660a-5429-403c-ad1f-09adc109738f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Get combination of replier tweetids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d756ff-0dfa-4584-928a-7e46bf97abb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "\n",
    "embedding_path = config['EMBEDDINGS_PATH']\n",
    "reply_multilanguage_embedding = embedding_path['reply_multilanguage_embedding']\n",
    "\n",
    "df_embedding = pd.read_pickle(reply_multilanguage_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c483631-accc-452d-a9c3-c4213bcb7ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unq = df_embedding.groupby(['poster_tweetid', 'replier_userid'])['replier_tweetid'].last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0818cd3-5113-4506-a7ca-5f431d4b60a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_unq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87ea7ed2-7f48-40b6-8800-4117cb4249e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_size = df_unq.groupby(['poster_tweetid'])['replier_tweetid'].nunique().to_frame('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9cbcd1-35d7-4b7e-b1ca-01890ab827c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_size['count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308f6e4-8e49-4e4d-91c2-56c67ceba0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_size.loc[(df_size['count'] <= 30000) & (df_size['count'] >= 20000)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402b679-0bac-40bc-b77b-6cb08fc7b965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def try_get_combination(df):\n",
    "    df_unq = df.groupby(['poster_tweetid', \n",
    "                                   'replier_userid'])['replier_tweetid'].last().reset_index()   \n",
    "    df_size = df_unq.groupby(['poster_tweetid'])[\n",
    "        'replier_tweetid'].nunique().to_frame('count').reset_index()\n",
    "    ids = df_size.loc[df_size['count'] < 100]['poster_tweetid']\n",
    "    \n",
    "    df_poster = df.loc[df['poster_tweetid'].isin(ids)]\n",
    "    \n",
    "    importlib.reload(config_hp)\n",
    "\n",
    "    config = config_hp.config()\n",
    "\n",
    "    embedding_path = config['EMBEDDINGS_PATH']\n",
    "\n",
    "    combination = embedding_path['combination']\n",
    "\n",
    "    print(len(df_poster))\n",
    "    \n",
    "    print('starting')\n",
    "    \n",
    "    df_comb = df_poster.groupby('poster_tweetid')['replier_tweetid'].apply(lambda x:\n",
    "        list(combinations(x, 2))).reset_index()\n",
    "    print('list here')\n",
    "    print(df_comb.info())\n",
    "\n",
    "    df_exploded = df_comb.explode('replier_tweetid')\n",
    "    df_exploded['replier_x'] = df_exploded['replier_tweetid'].apply(\n",
    "        lambda x: x[0])\n",
    "    df_exploded['replier_y'] = df_exploded['replier_tweetid'].apply(\n",
    "        lambda x: x[1])\n",
    "    df_emb = df_exploded.merge(df[['replier_tweetid', 'embeddings']],\n",
    "                  left_on='replier_x',\n",
    "                  right_on='replier_tweetid'\n",
    "                 )\n",
    "    df_emb = df_emb.merge(df[['replier_tweetid', 'embeddings']],\n",
    "                      left_on='replier_y',\n",
    "                      right_on='replier_tweetid'\n",
    "                     )\n",
    "    print(df_emb.info())\n",
    "    print('Embdding here')\n",
    "\n",
    "    def get_cosine(df):\n",
    "        '''\n",
    "        Get the cosine similarity of the vector list\n",
    "        :param vector_list: list of embedding vectors\n",
    "\n",
    "        :return list\n",
    "        '''\n",
    "\n",
    "        df['cosine'] = df.apply(lambda x: round(\n",
    "                cosine_similarity(x.embeddings_x, x.embeddings_y)[0][0],\n",
    "                2),\n",
    "            axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    df_emb_cosine = get_cosine(df_emb)\n",
    "    \n",
    "    return df_emb_cosine[['poster_tweetid', 'replier_x', 'replier_y', 'cosine']]\n",
    "    \n",
    "df_comb = try_get_combination(df_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b32163-bbe7-4883-ad0a-77d91863c285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed214834-239a-47a7-be4d-8dd310d13178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(config_hp)\n",
    "\n",
    "config = config_hp.config()\n",
    "\n",
    "embedding_path = config['EMBEDDINGS_PATH']\n",
    "\n",
    "combination = embedding_path['combination']\n",
    "\n",
    "df_comb.to_pickle(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743372bf-9a87-445a-9ffe-60e44b469d9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **Calculate cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5030ba73-9928-4564-ae04-2e81b6106839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_exploded = df_comb.explode('replier_tweetid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5168297e-4144-4e09-b2ac-cfd1349502b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_exploded['replier_x'] = df_exploded['replier_tweetid'].apply(\n",
    "    lambda x: x[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "997a78d8-2821-46cc-878d-11335b5b7e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_exploded['replier_y'] = df_exploded['replier_tweetid'].apply(\n",
    "    lambda x: x[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074922f1-1a13-4a85-be05-033c7e904b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_emb = df_exploded.merge(df_embedding[['replier_tweetid', 'embeddings']],\n",
    "                  left_on='replier_x',\n",
    "                  right_on='replier_tweetid'\n",
    "                 )\n",
    "df_emb = df_emb.merge(df_embedding[['replier_tweetid', 'embeddings']],\n",
    "                  left_on='replier_y',\n",
    "                  right_on='replier_tweetid'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d5d7b8-a734-4c85-818f-8e8f178e48d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['poster_tweetid', 'replier_tweetid_x', 'replier_x', 'replier_y',\n",
       "       'replier_tweetid_y', 'embeddings_x', 'replier_tweetid', 'embeddings_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "329d40eb-2ab7-47b1-96c6-5df53d4aa25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine(df):\n",
    "    '''\n",
    "    Get the cosine similarity of the vector list\n",
    "    :param vector_list: list of embedding vectors\n",
    "    \n",
    "    :return list\n",
    "    '''\n",
    "    \n",
    "    df['cosine'] = df.apply(lambda x: round(\n",
    "            cosine_similarity(x.embeddings_x, x.embeddings_y)[0][0],\n",
    "            2),\n",
    "        axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54b0c313-d0fc-4154-97d9-4179833ec181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_emb_cosine = get_cosine(df_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0ce9135-7cba-47ce-9405-37c91e4cddfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poster_tweetid</th>\n",
       "      <th>replier_x</th>\n",
       "      <th>replier_y</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1170262342606700544</td>\n",
       "      <td>1170377372920680450</td>\n",
       "      <td>1170290164276633600</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1170262342606700544</td>\n",
       "      <td>1170377372920680450</td>\n",
       "      <td>1170299388486402048</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1170262342606700544</td>\n",
       "      <td>1170290164276633600</td>\n",
       "      <td>1170299388486402048</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1170262342606700544</td>\n",
       "      <td>1170377372920680450</td>\n",
       "      <td>1170291675039784962</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1170262342606700544</td>\n",
       "      <td>1170290164276633600</td>\n",
       "      <td>1170291675039784962</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1175020156231278592</td>\n",
       "      <td>1175036782582423553</td>\n",
       "      <td>1175036516923596800</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>1175020156231278592</td>\n",
       "      <td>1175036056082812928</td>\n",
       "      <td>1175036516923596800</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1175020156231278592</td>\n",
       "      <td>1175035467278036992</td>\n",
       "      <td>1175036516923596800</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>1175020156231278592</td>\n",
       "      <td>1175038138152079360</td>\n",
       "      <td>1175036516923596800</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1184015152846376960</td>\n",
       "      <td>1185270126872018944</td>\n",
       "      <td>1184048523601469440</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          poster_tweetid            replier_x            replier_y  cosine\n",
       "0    1170262342606700544  1170377372920680450  1170290164276633600    0.31\n",
       "1    1170262342606700544  1170377372920680450  1170299388486402048    0.25\n",
       "2    1170262342606700544  1170290164276633600  1170299388486402048    0.33\n",
       "3    1170262342606700544  1170377372920680450  1170291675039784962    0.27\n",
       "4    1170262342606700544  1170290164276633600  1170291675039784962    0.38\n",
       "..                   ...                  ...                  ...     ...\n",
       "620  1175020156231278592  1175036782582423553  1175036516923596800    0.15\n",
       "621  1175020156231278592  1175036056082812928  1175036516923596800    0.07\n",
       "622  1175020156231278592  1175035467278036992  1175036516923596800    0.28\n",
       "623  1175020156231278592  1175038138152079360  1175036516923596800    0.32\n",
       "624  1184015152846376960  1185270126872018944  1184048523601469440    0.14\n",
       "\n",
       "[625 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb_cosine[['poster_tweetid', 'replier_x', 'replier_y', 'cosine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf669930-9064-499f-a376-8a14c01c0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
